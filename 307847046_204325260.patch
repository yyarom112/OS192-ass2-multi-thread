diff --git a/Makefile b/Makefile
index 3718622..b48f2de 100644
--- a/Makefile
+++ b/Makefile
@@ -143,7 +143,7 @@ tags: $(OBJS) entryother.S _init
 vectors.S: vectors.pl
 	./vectors.pl > vectors.S
 
-ULIB = ulib.o usys.o printf.o umalloc.o
+ULIB = ulib.o usys.o printf.o umalloc.o tournament_tree.o
 
 _%: %.o $(ULIB)
 	$(LD) $(LDFLAGS) -N -e main -Ttext 0 -o $@ $^
@@ -181,6 +181,7 @@ UPROGS=\
 	_usertests\
 	_wc\
 	_zombie\
+	_sanity\
 
 fs.img: mkfs README $(UPROGS)
 	./mkfs fs.img README $(UPROGS)
@@ -249,7 +250,7 @@ qemu-nox-gdb: fs.img xv6.img .gdbinit
 
 EXTRA=\
 	mkfs.c ulib.c user.h cat.c echo.c forktest.c grep.c kill.c\
-	ln.c ls.c mkdir.c rm.c stressfs.c usertests.c wc.c zombie.c\
+	ln.c ls.c mkdir.c rm.c stressfs.c usertests.c wc.c zombie.c sanity.c tournament_tree.c\
 	printf.c umalloc.c\
 	README dot-bochsrc *.pl toc.* runoff runoff1 runoff.list\
 	.gdbinit.tmpl gdbutil\
diff --git a/defs.h b/defs.h
index 82fb982..a8d2d45 100644
--- a/defs.h
+++ b/defs.h
@@ -11,180 +11,308 @@ struct stat;
 struct superblock;
 
 // bio.c
-void            binit(void);
-struct buf*     bread(uint, uint);
-void            brelse(struct buf*);
-void            bwrite(struct buf*);
+void binit(void);
+
+struct buf *bread(uint, uint);
+
+void brelse(struct buf *);
+
+void bwrite(struct buf *);
 
 // console.c
-void            consoleinit(void);
-void            cprintf(char*, ...);
-void            consoleintr(int(*)(void));
-void            panic(char*) __attribute__((noreturn));
+void consoleinit(void);
+
+void cprintf(char *, ...);
+
+void consoleintr(int(*)(void));
+
+void panic(char *) __attribute__((noreturn));
 
 // exec.c
-int             exec(char*, char**);
+int exec(char *, char **);
 
 // file.c
-struct file*    filealloc(void);
-void            fileclose(struct file*);
-struct file*    filedup(struct file*);
-void            fileinit(void);
-int             fileread(struct file*, char*, int n);
-int             filestat(struct file*, struct stat*);
-int             filewrite(struct file*, char*, int n);
+struct file *filealloc(void);
+
+void fileclose(struct file *);
+
+struct file *filedup(struct file *);
+
+void fileinit(void);
+
+int fileread(struct file *, char *, int n);
+
+int filestat(struct file *, struct stat *);
+
+int filewrite(struct file *, char *, int n);
 
 // fs.c
-void            readsb(int dev, struct superblock *sb);
-int             dirlink(struct inode*, char*, uint);
-struct inode*   dirlookup(struct inode*, char*, uint*);
-struct inode*   ialloc(uint, short);
-struct inode*   idup(struct inode*);
-void            iinit(int dev);
-void            ilock(struct inode*);
-void            iput(struct inode*);
-void            iunlock(struct inode*);
-void            iunlockput(struct inode*);
-void            iupdate(struct inode*);
-int             namecmp(const char*, const char*);
-struct inode*   namei(char*);
-struct inode*   nameiparent(char*, char*);
-int             readi(struct inode*, char*, uint, uint);
-void            stati(struct inode*, struct stat*);
-int             writei(struct inode*, char*, uint, uint);
+void readsb(int dev, struct superblock *sb);
+
+int dirlink(struct inode *, char *, uint);
+
+struct inode *dirlookup(struct inode *, char *, uint *);
+
+struct inode *ialloc(uint, short);
+
+struct inode *idup(struct inode *);
+
+void iinit(int dev);
+
+void ilock(struct inode *);
+
+void iput(struct inode *);
+
+void iunlock(struct inode *);
+
+void iunlockput(struct inode *);
+
+void iupdate(struct inode *);
+
+int namecmp(const char *, const char *);
+
+struct inode *namei(char *);
+
+struct inode *nameiparent(char *, char *);
+
+int readi(struct inode *, char *, uint, uint);
+
+void stati(struct inode *, struct stat *);
+
+int writei(struct inode *, char *, uint, uint);
 
 // ide.c
-void            ideinit(void);
-void            ideintr(void);
-void            iderw(struct buf*);
+void ideinit(void);
+
+void ideintr(void);
+
+void iderw(struct buf *);
 
 // ioapic.c
-void            ioapicenable(int irq, int cpu);
-extern uchar    ioapicid;
-void            ioapicinit(void);
+void ioapicenable(int irq, int cpu);
+
+extern uchar ioapicid;
+
+void ioapicinit(void);
 
 // kalloc.c
-char*           kalloc(void);
-void            kfree(char*);
-void            kinit1(void*, void*);
-void            kinit2(void*, void*);
+char *kalloc(void);
+
+void kfree(char *);
+
+void kinit1(void *, void *);
+
+void kinit2(void *, void *);
 
 // kbd.c
-void            kbdintr(void);
+void kbdintr(void);
 
 // lapic.c
-void            cmostime(struct rtcdate *r);
-int             lapicid(void);
-extern volatile uint*    lapic;
-void            lapiceoi(void);
-void            lapicinit(void);
-void            lapicstartap(uchar, uint);
-void            microdelay(int);
+void cmostime(struct rtcdate *r);
+
+int lapicid(void);
+
+extern volatile uint *lapic;
+
+void lapiceoi(void);
+
+void lapicinit(void);
+
+void lapicstartap(uchar, uint);
+
+void microdelay(int);
 
 // log.c
-void            initlog(int dev);
-void            log_write(struct buf*);
-void            begin_op();
-void            end_op();
+void initlog(int dev);
+
+void log_write(struct buf *);
+
+void begin_op();
+
+void end_op();
 
 // mp.c
-extern int      ismp;
-void            mpinit(void);
+extern int ismp;
+
+void mpinit(void);
 
 // picirq.c
-void            picenable(int);
-void            picinit(void);
+void picenable(int);
+
+void picinit(void);
 
 // pipe.c
-int             pipealloc(struct file**, struct file**);
-void            pipeclose(struct pipe*, int);
-int             piperead(struct pipe*, char*, int);
-int             pipewrite(struct pipe*, char*, int);
+int pipealloc(struct file **, struct file **);
+
+void pipeclose(struct pipe *, int);
+
+int piperead(struct pipe *, char *, int);
+
+int pipewrite(struct pipe *, char *, int);
 
 //PAGEBREAK: 16
 // proc.c
-int             cpuid(void);
-void            exit(void);
-int             fork(void);
-int             growproc(int);
-int             kill(int);
-struct cpu*     mycpu(void);
-struct proc*    myproc();
-void            pinit(void);
-void            procdump(void);
-void            scheduler(void) __attribute__((noreturn));
-void            sched(void);
-void            setproc(struct proc*);
-void            sleep(void*, struct spinlock*);
-void            userinit(void);
-int             wait(void);
-void            wakeup(void*);
-void            yield(void);
+int cpuid(void);
+
+void exit(void);
+
+int fork(void);
+
+int growproc(int);
+
+int kill(int);
+
+struct cpu *mycpu(void);
+
+struct proc *myproc();
+
+struct thread *mythread();
+
+struct spinlock *mySpinlock();
+
+void pinit(void);
+
+void procdump(void);
+
+void scheduler(void) __attribute__((noreturn));
+
+void sched(void);
+
+void setproc(struct proc *);
+
+void sleep(void *, struct spinlock *);
+
+void userinit(void);
+
+int wait(void);
+
+void wakeup(void *);
+
+void yield(void);
+
+void cprintState(struct thread *);
+
+void exitThread(void);
+
+int kthread_create(void (*start_func)(), void *stack);
+
+int kthread_id();
+
+void kthread_exit();
+
+int kthread_join(int thread_id);
+
+int kthread_mutex_alloc();
+
+int kthread_mutex_dealloc(int mutex_id);
+
+int kthread_mutex_lock(int mutex_id);
+
+int kthread_mutex_unlock(int mutex_id);
+
 
 // swtch.S
-void            swtch(struct context**, struct context*);
+void swtch(struct context **, struct context *);
 
 // spinlock.c
-void            acquire(struct spinlock*);
-void            getcallerpcs(void*, uint*);
-int             holding(struct spinlock*);
-void            initlock(struct spinlock*, char*);
-void            release(struct spinlock*);
-void            pushcli(void);
-void            popcli(void);
+void acquire(struct spinlock *);
+
+void getcallerpcs(void *, uint *);
+
+int holding(struct spinlock *);
+
+void initlock(struct spinlock *, char *);
+
+void release(struct spinlock *);
+
+void pushcli(void);
+
+void popcli(void);
 
 // sleeplock.c
-void            acquiresleep(struct sleeplock*);
-void            releasesleep(struct sleeplock*);
-int             holdingsleep(struct sleeplock*);
-void            initsleeplock(struct sleeplock*, char*);
+void acquiresleep(struct sleeplock *);
+
+void releasesleep(struct sleeplock *);
+
+int holdingsleep(struct sleeplock *);
+
+void initsleeplock(struct sleeplock *, char *);
 
 // string.c
-int             memcmp(const void*, const void*, uint);
-void*           memmove(void*, const void*, uint);
-void*           memset(void*, int, uint);
-char*           safestrcpy(char*, const char*, int);
-int             strlen(const char*);
-int             strncmp(const char*, const char*, uint);
-char*           strncpy(char*, const char*, int);
+int memcmp(const void *, const void *, uint);
+
+void *memmove(void *, const void *, uint);
+
+void *memset(void *, int, uint);
+
+char *safestrcpy(char *, const char *, int);
+
+int strlen(const char *);
+
+int strncmp(const char *, const char *, uint);
+
+char *strncpy(char *, const char *, int);
 
 // syscall.c
-int             argint(int, int*);
-int             argptr(int, char**, int);
-int             argstr(int, char**);
-int             fetchint(uint, int*);
-int             fetchstr(uint, char**);
-void            syscall(void);
+int argint(int, int *);
+
+int argptr(int, char **, int);
+
+int argstr(int, char **);
+
+int fetchint(uint, int *);
+
+int fetchstr(uint, char **);
+
+void syscall(void);
 
 // timer.c
-void            timerinit(void);
+void timerinit(void);
 
 // trap.c
-void            idtinit(void);
-extern uint     ticks;
-void            tvinit(void);
+void idtinit(void);
+
+extern uint ticks;
+
+void tvinit(void);
+
 extern struct spinlock tickslock;
 
 // uart.c
-void            uartinit(void);
-void            uartintr(void);
-void            uartputc(int);
+void uartinit(void);
+
+void uartintr(void);
+
+void uartputc(int);
 
 // vm.c
-void            seginit(void);
-void            kvmalloc(void);
-pde_t*          setupkvm(void);
-char*           uva2ka(pde_t*, char*);
-int             allocuvm(pde_t*, uint, uint);
-int             deallocuvm(pde_t*, uint, uint);
-void            freevm(pde_t*);
-void            inituvm(pde_t*, char*, uint);
-int             loaduvm(pde_t*, char*, struct inode*, uint, uint);
-pde_t*          copyuvm(pde_t*, uint);
-void            switchuvm(struct proc*);
-void            switchkvm(void);
-int             copyout(pde_t*, uint, void*, uint);
-void            clearpteu(pde_t *pgdir, char *uva);
+void seginit(void);
+
+void kvmalloc(void);
+
+pde_t *setupkvm(void);
+
+char *uva2ka(pde_t *, char *);
+
+int allocuvm(pde_t *, uint, uint);
+
+int deallocuvm(pde_t *, uint, uint);
+
+void freevm(pde_t *);
+
+void inituvm(pde_t *, char *, uint);
+
+int loaduvm(pde_t *, char *, struct inode *, uint, uint);
+
+pde_t *copyuvm(pde_t *, uint);
+
+void switchuvm(struct thread *, struct proc *);
+
+void switchkvm(void);
+
+int copyout(pde_t *, uint, void *, uint);
+
+void clearpteu(pde_t *pgdir, char *uva);
 
 // number of elements in fixed-size array
 #define NELEM(x) (sizeof(x)/sizeof((x)[0]))
diff --git a/exec.c b/exec.c
index b40134f..fe66eb4 100644
--- a/exec.c
+++ b/exec.c
@@ -8,107 +8,144 @@
 #include "elf.h"
 
 int
-exec(char *path, char **argv)
-{
-  char *s, *last;
-  int i, off;
-  uint argc, sz, sp, ustack[3+MAXARG+1];
-  struct elfhdr elf;
-  struct inode *ip;
-  struct proghdr ph;
-  pde_t *pgdir, *oldpgdir;
-  struct proc *curproc = myproc();
+exec(char *path, char **argv) {
+    char *s, *last;
+    int i, off;
+    uint argc, sz, sp, ustack[3 + MAXARG + 1];
+    struct elfhdr elf;
+    struct inode *ip;
+    struct proghdr ph;
+    pde_t *pgdir, *oldpgdir;
+    struct proc *curproc = myproc();
+    struct thread *curthread = mythread();
+    struct thread *t;
 
-  begin_op();
+    if(mythread()->shouldDie){
+        kthread_exit();
+    }
 
-  if((ip = namei(path)) == 0){
-    end_op();
-    cprintf("exec: fail\n");
-    return -1;
-  }
-  ilock(ip);
-  pgdir = 0;
+    acquire(mySpinlock());
+    for (t = curproc->ttable; t < &(curproc->ttable[NTHREAD]); t++) {
+        if (t->tid != curthread->tid)
+            t->shouldDie = 1;
+        if (t->state == T_SLEEPING)
+            t->state = T_RUNNABLE;
+    }
+    release(mySpinlock());
+    int numthread=1000;
+    while(numthread>1){
+        numthread=0;
+        for(t=curproc->ttable;t<&(curproc->ttable[NTHREAD]);t++){
+            if (t->state == T_SLEEPING){
+                t->state = T_RUNNABLE;
+            }
+            if(t->state==T_ZOMBIE){
+                kfree(t->kstack);
+                t->kstack = 0;
+                t->tid = 0;
+                t->state = T_UNUSED;
+                curproc->numOfthread--;
+            }
+            else{
+                if(t->state!=T_UNUSED){
+                    numthread++;
+                }
+            }
+        }
+    }
 
-  // Check ELF header
-  if(readi(ip, (char*)&elf, 0, sizeof(elf)) != sizeof(elf))
-    goto bad;
-  if(elf.magic != ELF_MAGIC)
-    goto bad;
+    begin_op();
 
-  if((pgdir = setupkvm()) == 0)
-    goto bad;
+    if ((ip = namei(path)) == 0) {
+        end_op();
+        cprintf("exec: fail\n");
+        return -1;
+    }
+    ilock(ip);
+    pgdir = 0;
 
-  // Load program into memory.
-  sz = 0;
-  for(i=0, off=elf.phoff; i<elf.phnum; i++, off+=sizeof(ph)){
-    if(readi(ip, (char*)&ph, off, sizeof(ph)) != sizeof(ph))
-      goto bad;
-    if(ph.type != ELF_PROG_LOAD)
-      continue;
-    if(ph.memsz < ph.filesz)
-      goto bad;
-    if(ph.vaddr + ph.memsz < ph.vaddr)
-      goto bad;
-    if((sz = allocuvm(pgdir, sz, ph.vaddr + ph.memsz)) == 0)
-      goto bad;
-    if(ph.vaddr % PGSIZE != 0)
-      goto bad;
-    if(loaduvm(pgdir, (char*)ph.vaddr, ip, ph.off, ph.filesz) < 0)
-      goto bad;
-  }
-  iunlockput(ip);
-  end_op();
-  ip = 0;
+    // Check ELF header
+    if (readi(ip, (char *) &elf, 0, sizeof(elf)) != sizeof(elf))
+        goto bad;
+    if (elf.magic != ELF_MAGIC)
+        goto bad;
 
-  // Allocate two pages at the next page boundary.
-  // Make the first inaccessible.  Use the second as the user stack.
-  sz = PGROUNDUP(sz);
-  if((sz = allocuvm(pgdir, sz, sz + 2*PGSIZE)) == 0)
-    goto bad;
-  clearpteu(pgdir, (char*)(sz - 2*PGSIZE));
-  sp = sz;
+    if ((pgdir = setupkvm()) == 0)
+        goto bad;
+
+    // Load program into memory.
+    sz = 0;
+    for (i = 0, off = elf.phoff; i < elf.phnum; i++, off += sizeof(ph)) {
+        if (readi(ip, (char *) &ph, off, sizeof(ph)) != sizeof(ph))
+            goto bad;
+        if (ph.type != ELF_PROG_LOAD)
+            continue;
+        if (ph.memsz < ph.filesz)
+            goto bad;
+        if (ph.vaddr + ph.memsz < ph.vaddr)
+            goto bad;
+        if ((sz = allocuvm(pgdir, sz, ph.vaddr + ph.memsz)) == 0)
+            goto bad;
+        if (ph.vaddr % PGSIZE != 0)
+            goto bad;
+        if (loaduvm(pgdir, (char *) ph.vaddr, ip, ph.off, ph.filesz) < 0)
+            goto bad;
+    }
+    iunlockput(ip);
+    end_op();
+    ip = 0;
+    acquire(mySpinlock());
+    // Allocate two pages at the next page boundary.
+    // Make the first inaccessible.  Use the second as the user stack.
+    sz = PGROUNDUP(sz);
+    if ((sz = allocuvm(pgdir, sz, sz + 2 * PGSIZE)) == 0)
+        goto bad;
+    clearpteu(pgdir, (char *) (sz - 2 * PGSIZE));
+    sp = sz;
 
-  // Push argument strings, prepare rest of stack in ustack.
-  for(argc = 0; argv[argc]; argc++) {
-    if(argc >= MAXARG)
-      goto bad;
-    sp = (sp - (strlen(argv[argc]) + 1)) & ~3;
-    if(copyout(pgdir, sp, argv[argc], strlen(argv[argc]) + 1) < 0)
-      goto bad;
-    ustack[3+argc] = sp;
-  }
-  ustack[3+argc] = 0;
+    // Push argument strings, prepare rest of stack in ustack.
+    for (argc = 0; argv[argc]; argc++) {
+        if (argc >= MAXARG)
+            goto bad;
+        sp = (sp - (strlen(argv[argc]) + 1)) & ~3;
+        if (copyout(pgdir, sp, argv[argc], strlen(argv[argc]) + 1) < 0)
+            goto bad;
+        ustack[3 + argc] = sp;
+    }
+    ustack[3 + argc] = 0;
 
-  ustack[0] = 0xffffffff;  // fake return PC
-  ustack[1] = argc;
-  ustack[2] = sp - (argc+1)*4;  // argv pointer
+    ustack[0] = 0xffffffff;  // fake return PC
+    ustack[1] = argc;
+    ustack[2] = sp - (argc + 1) * 4;  // argv pointer
 
-  sp -= (3+argc+1) * 4;
-  if(copyout(pgdir, sp, ustack, (3+argc+1)*4) < 0)
-    goto bad;
+    sp -= (3 + argc + 1) * 4;
+    if (copyout(pgdir, sp, ustack, (3 + argc + 1) * 4) < 0)
+        goto bad;
 
-  // Save program name for debugging.
-  for(last=s=path; *s; s++)
-    if(*s == '/')
-      last = s+1;
-  safestrcpy(curproc->name, last, sizeof(curproc->name));
+    // Save program name for debugging.
+    for (last = s = path; *s; s++)
+        if (*s == '/')
+            last = s + 1;
+    safestrcpy(curproc->name, last, sizeof(curproc->name));
 
-  // Commit to the user image.
-  oldpgdir = curproc->pgdir;
-  curproc->pgdir = pgdir;
-  curproc->sz = sz;
-  curproc->tf->eip = elf.entry;  // main
-  curproc->tf->esp = sp;
-  switchuvm(curproc);
-  freevm(oldpgdir);
-  return 0;
+    // Commit to the user image.
+    oldpgdir = curproc->pgdir;
+    curproc->pgdir = pgdir;
+    curproc->sz = sz;
+    curthread->tf->eip = elf.entry;  // main
+    curthread->tf->esp = sp;
+    switchuvm(curthread,curproc);
+    release(mySpinlock());
+    freevm(oldpgdir);
+    return 0;
 
- bad:
-  if(pgdir)
-    freevm(pgdir);
-  if(ip){
-    iunlockput(ip);
-    end_op();
-  }
-  return -1;
+    bad:
+    if (pgdir)
+        freevm(pgdir);
+    if (ip) {
+        iunlockput(ip);
+        end_op();
+    }
+    release(mySpinlock());
+    return -1;
 }
diff --git a/kthread.h b/kthread.h
index a0cdd0d..ca57c7c 100644
--- a/kthread.h
+++ b/kthread.h
@@ -1,3 +1,6 @@
+#include "spinlock.h"
+
+
 #define MAX_STACK_SIZE 4000
 #define MAX_MUTEXES 64
 
@@ -5,6 +8,7 @@
         The API of the KLT package
  ********************************/
 
+
 int kthread_create(void (*start_func)(), void* stack);
 int kthread_id();
 void kthread_exit();
@@ -15,7 +19,15 @@ int kthread_mutex_dealloc(int mutex_id);
 int kthread_mutex_lock(int mutex_id);
 int kthread_mutex_unlock(int mutex_id);
 
-trnmnt_tree* trnmnt_tree_alloc(int depth);
-int trnmnt_tree_dealloc(trnmnt_tree* tree);
-int trnmnt_tree_acquire(trnmnt_tree* tree,int ID);
-int trnmnt_tree_release(trnmnt_tree* tree,int ID);
+enum mutexState {UNINITIALIZED, OPEN , CLOSE };
+struct mutex{
+    int mid;
+    int lock;
+    int numOfWaiting;
+    struct spinlock mutexLock;
+    enum mutexState state;
+    struct thread* holding;
+    int pid_holder;
+}mutex;
+
+
diff --git a/param.h b/param.h
index a7e90ef..bba0fce 100644
--- a/param.h
+++ b/param.h
@@ -11,4 +11,5 @@
 #define LOGSIZE      (MAXOPBLOCKS*3)  // max data blocks in on-disk log
 #define NBUF         (MAXOPBLOCKS*3)  // size of disk block cache
 #define FSSIZE       1000  // size of file system in blocks
+#define NTHREAD      16  //number of thread in proccess
 
diff --git a/proc.c b/proc.c
index 806b1b1..18b77d6 100644
--- a/proc.c
+++ b/proc.c
@@ -5,64 +5,134 @@
 #include "mmu.h"
 #include "x86.h"
 #include "proc.h"
-#include "spinlock.h"
+#include "kthread.h"
 
 struct {
-  struct spinlock lock;
-  struct proc proc[NPROC];
+    struct spinlock lock;
+    struct proc proc[NPROC];
 } ptable;
 
+
+struct {
+    struct spinlock lock;
+    struct mutex mutex[MAX_MUTEXES];
+} mtable;
+
 static struct proc *initproc;
 
 int nextpid = 1;
+int nexttid = 1;
+int nextmid = 1;
+
+
 extern void forkret(void);
+
 extern void trapret(void);
 
 static void wakeup1(void *chan);
 
 void
-pinit(void)
-{
-  initlock(&ptable.lock, "ptable");
+pinit(void) {
+    initlock(&mtable.lock, "mtable");
+    initlock(&ptable.lock, "ptable");
+    for (int i = 0; i < MAX_MUTEXES; i++) {
+        initlock(&mtable.mutex[i].mutexLock, "mutexLock");
+    }
+}
+
+void cprintState(struct thread *t) {
+    switch (t->state) {
+        case T_ZOMBIE:
+            cprintf("thread id %d and he killed=%d that is father is %s in state T_ZOMBIE\n", t->tid,t->shouldDie, t->parent->name);
+            break;
+        case T_RUNNABLE:
+            cprintf("thread id %d and he killed=%d that is father is %s in state T_RUNNABLE\n",t->tid,t->shouldDie, t->parent->name);
+            break;
+        case T_SLEEPING:
+            cprintf("thread id %d and he killed=%d that is father is %s in state T_SLEEPING\n", t->tid,t->shouldDie, t->parent->name);
+            break;
+        case T_UNUSED:
+            cprintf("thread id %d and he killed=%d that is father is %s in state T_UNUSED\n", t->tid,t->shouldDie, t->parent->name);
+            break;
+        case T_EMBRYO:
+            cprintf("thread id %d and he killed=%d that is father is %s in state T_EMBRYO\n", t->tid,t->shouldDie, t->parent->name);
+            break;
+        case T_RUNNING:
+            cprintf("thread id %d and he killed=%d that is father is %s in state T_RUNNING\n", t->tid,t->shouldDie, t->parent->name);
+            break;
+    }
+}
+
+
+void cprintMutexState(struct mutex *m) {
+    switch (m->state) {
+        case UNINITIALIZED:
+            cprintf("mutex id is %d and is state = UNINITIALIZED\n", m->mid);
+            break;
+        case OPEN:
+            cprintf("mutex id is %d and is state = OPEN\n", m->mid);
+            break;
+        case CLOSE:
+            cprintf("mutex id is %d and is state = CLOSE\n", m->mid);
+            break;
+    }
+}
+
+struct spinlock *
+mySpinlock() {
+    return &ptable.lock;
 }
 
 // Must be called with interrupts disabled
 int
 cpuid() {
-  return mycpu()-cpus;
+    return mycpu() - cpus;
 }
 
 // Must be called with interrupts disabled to avoid the caller being
 // rescheduled between reading lapicid and running through the loop.
-struct cpu*
-mycpu(void)
-{
-  int apicid, i;
-  
-  if(readeflags()&FL_IF)
-    panic("mycpu called with interrupts enabled\n");
-  
-  apicid = lapicid();
-  // APIC IDs are not guaranteed to be contiguous. Maybe we should have
-  // a reverse map, or reserve a register to store &cpus[i].
-  for (i = 0; i < ncpu; ++i) {
-    if (cpus[i].apicid == apicid)
-      return &cpus[i];
-  }
-  panic("unknown apicid\n");
+struct cpu *
+mycpu(void) {
+    int apicid, i;
+
+    if (readeflags() & FL_IF)
+        panic("mycpu called with interrupts enabled\n");
+
+    apicid = lapicid();
+    // APIC IDs are not guaranteed to be contiguous. Maybe we should have
+    // a reverse map, or reserve a register to store &cpus[i].
+    for (i = 0; i < ncpu; ++i) {
+        if (cpus[i].apicid == apicid)
+            return &cpus[i];
+    }
+    panic("unknown apicid\n");
 }
 
 // Disable interrupts so that we are not rescheduled
 // while reading proc from the cpu structure
-struct proc*
+struct proc *
 myproc(void) {
-  struct cpu *c;
-  struct proc *p;
-  pushcli();
-  c = mycpu();
-  p = c->proc;
-  popcli();
-  return p;
+    struct cpu *c;
+    struct proc *p;
+    pushcli();
+    c = mycpu();
+    p = c->proc;
+    popcli();
+    return p;
+}
+
+
+// Disable interrupts so that we are not rescheduled
+// while reading thread from the cpu structure
+struct thread *
+mythread(void) {
+    struct cpu *c;
+    struct thread *t;
+    pushcli();
+    c = mycpu();
+    t = c->thread;
+    popcli();
+    return t;
 }
 
 //PAGEBREAK: 32
@@ -70,245 +140,347 @@ myproc(void) {
 // If found, change state to EMBRYO and initialize
 // state required to run in the kernel.
 // Otherwise return 0.
-static struct proc*
-allocproc(void)
-{
-  struct proc *p;
-  char *sp;
-
-  acquire(&ptable.lock);
-
-  for(p = ptable.proc; p < &ptable.proc[NPROC]; p++)
-    if(p->state == UNUSED)
-      goto found;
+static struct proc *
+allocproc(void) {
+    struct proc *p;
+    acquire(&ptable.lock);
+    for (p = ptable.proc; p < &ptable.proc[NPROC]; p++) {
+        if (p->state == UNUSED)
+            goto found;
+    }
+    release(&ptable.lock);
+    return 0;
 
-  release(&ptable.lock);
-  return 0;
+    found:
+    p->state = USED;
+    p->pid = nextpid++;
+    release(&ptable.lock);
 
-found:
-  p->state = EMBRYO;
-  p->pid = nextpid++;
+    return p;
+}
 
-  release(&ptable.lock);
 
-  // Allocate kernel stack.
-  if((p->kstack = kalloc()) == 0){
-    p->state = UNUSED;
+static struct thread *
+allocthread(struct proc *p) {
+    struct thread *t;
+    char *sp;
+    int i;
+    acquire(&ptable.lock);
+    for (i = 1, t = p->ttable; t < &p->ttable[NTHREAD]; t++, i++) {
+        if (t->state == T_UNUSED) {
+            goto found;
+        }
+    }
+    release(&ptable.lock);
     return 0;
-  }
-  sp = p->kstack + KSTACKSIZE;
-
-  // Leave room for trap frame.
-  sp -= sizeof *p->tf;
-  p->tf = (struct trapframe*)sp;
-
-  // Set up new context to start executing at forkret,
-  // which returns to trapret.
-  sp -= 4;
-  *(uint*)sp = (uint)trapret;
 
-  sp -= sizeof *p->context;
-  p->context = (struct context*)sp;
-  memset(p->context, 0, sizeof *p->context);
-  p->context->eip = (uint)forkret;
+    found:
+    t->state = T_EMBRYO;
+    t->tid = nexttid++;
+    t->parent = p;
+    t->next_thread = 0;
+    t->mutex_flag = 0;
+    t->shouldDie = 0;
+    release(&ptable.lock);
 
-  return p;
+    // Allocate kernel stack.
+    if ((t->kstack = kalloc()) == 0) {
+        p->state = UNUSED;
+        t->state = T_UNUSED;
+        return 0;
+    }
+    sp = t->kstack + KSTACKSIZE;
+
+    // Leave room for trap frame.
+    sp -= sizeof *t->tf;
+    t->tf = (struct trapframe *) sp;
+
+    // Set up new context to start executing at forkret,
+    // which returns to trapret.
+    sp -= 4;
+    *(uint *) sp = (uint) trapret;
+
+    sp -= sizeof *t->context;
+    t->context = (struct context *) sp;
+    memset(t->context, 0, sizeof *t->context);
+    t->context->eip = (uint) forkret;
+    p->numOfthread++;
+    return t;
 }
 
 //PAGEBREAK: 32
 // Set up first user process.
 void
-userinit(void)
-{
-  struct proc *p;
-  extern char _binary_initcode_start[], _binary_initcode_size[];
-
-  p = allocproc();
-  
-  initproc = p;
-  if((p->pgdir = setupkvm()) == 0)
-    panic("userinit: out of memory?");
-  inituvm(p->pgdir, _binary_initcode_start, (int)_binary_initcode_size);
-  p->sz = PGSIZE;
-  memset(p->tf, 0, sizeof(*p->tf));
-  p->tf->cs = (SEG_UCODE << 3) | DPL_USER;
-  p->tf->ds = (SEG_UDATA << 3) | DPL_USER;
-  p->tf->es = p->tf->ds;
-  p->tf->ss = p->tf->ds;
-  p->tf->eflags = FL_IF;
-  p->tf->esp = PGSIZE;
-  p->tf->eip = 0;  // beginning of initcode.S
-
-  safestrcpy(p->name, "initcode", sizeof(p->name));
-  p->cwd = namei("/");
-
-  // this assignment to p->state lets other cores
-  // run this process. the acquire forces the above
-  // writes to be visible, and the lock is also needed
-  // because the assignment might not be atomic.
-  acquire(&ptable.lock);
-
-  p->state = RUNNABLE;
-
-  release(&ptable.lock);
+userinit(void) {
+    struct proc *p;
+    struct thread *t;
+    extern char _binary_initcode_start[], _binary_initcode_size[];
+
+    p = allocproc();
+    t = allocthread(p);
+
+    initproc = p;
+    if ((p->pgdir = setupkvm()) == 0)
+        panic("userinit: out of memory?");
+    inituvm(p->pgdir, _binary_initcode_start, (int) _binary_initcode_size);
+    p->sz = PGSIZE;
+    memset(t->tf, 0, sizeof(*t->tf));
+    t->tf->cs = (SEG_UCODE << 3) | DPL_USER;
+    t->tf->ds = (SEG_UDATA << 3) | DPL_USER;
+    t->tf->es = t->tf->ds;
+    t->tf->ss = t->tf->ds;
+    t->tf->eflags = FL_IF;
+    t->tf->esp = PGSIZE;
+    t->tf->eip = 0;  // beginning of initcode.S
+
+    safestrcpy(p->name, "initcode", sizeof(p->name));
+    safestrcpy(t->name, "initcodeThread", sizeof(t->name));
+
+    p->cwd = namei("/");
+
+    // this assignment to p->state lets other cores
+    // run this process. the acquire forces the above
+    // writes to be visible, and the lock is also needed
+    // because the assignment might not be atomic.
+    acquire(&ptable.lock);
+
+    p->state = USED;
+    t->state = T_RUNNABLE;
+
+    release(&ptable.lock);
 }
 
 // Grow current process's memory by n bytes.
 // Return 0 on success, -1 on failure.
 int
-growproc(int n)
-{
-  uint sz;
-  struct proc *curproc = myproc();
-
-  sz = curproc->sz;
-  if(n > 0){
-    if((sz = allocuvm(curproc->pgdir, sz, sz + n)) == 0)
-      return -1;
-  } else if(n < 0){
-    if((sz = deallocuvm(curproc->pgdir, sz, sz + n)) == 0)
-      return -1;
-  }
-  curproc->sz = sz;
-  switchuvm(curproc);
-  return 0;
+growproc(int n) {
+    uint sz;
+    struct proc *curproc = myproc();
+    struct thread *curthread = mythread();
+
+    acquire(&ptable.lock);
+    sz = curproc->sz;
+    if (n > 0) {
+        if ((sz = allocuvm(curproc->pgdir, sz, sz + n)) == 0) {
+            release(&ptable.lock);
+            return -1;
+
+        }
+    } else if (n < 0) {
+        if ((sz = deallocuvm(curproc->pgdir, sz, sz + n)) == 0) {
+            release(&ptable.lock);
+            return -1;
+        }
+    }
+    curproc->sz = sz;
+    release(&ptable.lock);
+
+    switchuvm(curthread, curproc);
+    return 0;
 }
 
 // Create a new process copying p as the parent.
 // Sets up stack to return as if from system call.
 // Caller must set state of returned proc to RUNNABLE.
 int
-fork(void)
-{
-  int i, pid;
-  struct proc *np;
-  struct proc *curproc = myproc();
-
-  // Allocate process.
-  if((np = allocproc()) == 0){
-    return -1;
-  }
+fork(void) {
+    int i, pid;
+    struct proc *np;
+    struct proc *curproc = myproc();
+    struct thread *curthread = mythread();
+    struct thread *nt;
+
+    // Allocate process.
+    if ((np = allocproc()) == 0) {
+        return -1;
+    }
+    if ((nt = allocthread(np)) == 0) {
+        return -1;
+    }
 
-  // Copy process state from proc.
-  if((np->pgdir = copyuvm(curproc->pgdir, curproc->sz)) == 0){
-    kfree(np->kstack);
-    np->kstack = 0;
-    np->state = UNUSED;
-    return -1;
-  }
-  np->sz = curproc->sz;
-  np->parent = curproc;
-  *np->tf = *curproc->tf;
+    // Copy process state from proc.
+    if ((np->pgdir = copyuvm(curproc->pgdir, curproc->sz)) == 0) {
+        kfree(nt->kstack);
+        nt->kstack = 0;
+        np->state = UNUSED;
+        nt->state = T_UNUSED;
+        return -1;
+    }
+    np->sz = curproc->sz;
+    np->parent = curproc;
+    *nt->tf = *curthread->tf;
 
-  // Clear %eax so that fork returns 0 in the child.
-  np->tf->eax = 0;
+    // Clear %eax so that fork returns 0 in the child.
+    nt->tf->eax = 0;
 
-  for(i = 0; i < NOFILE; i++)
-    if(curproc->ofile[i])
-      np->ofile[i] = filedup(curproc->ofile[i]);
-  np->cwd = idup(curproc->cwd);
+    for (i = 0; i < NOFILE; i++)
+        if (curproc->ofile[i])
+            np->ofile[i] = filedup(curproc->ofile[i]);
+    np->cwd = idup(curproc->cwd);
 
-  safestrcpy(np->name, curproc->name, sizeof(curproc->name));
+    safestrcpy(np->name, curproc->name, sizeof(curproc->name));
+    safestrcpy(nt->name, curthread->name, sizeof(curthread->name));
 
-  pid = np->pid;
 
-  acquire(&ptable.lock);
+    pid = np->pid;
 
-  np->state = RUNNABLE;
+    acquire(&ptable.lock);
 
-  release(&ptable.lock);
+    np->state = USED;
+    nt->state = T_RUNNABLE;
 
-  return pid;
+    release(&ptable.lock);
+
+    return pid;
 }
 
 // Exit the current process.  Does not return.
 // An exited process remains in the zombie state
 // until its parent calls wait() to find out it exited.
 void
-exit(void)
-{
-  struct proc *curproc = myproc();
-  struct proc *p;
-  int fd;
+exit(void) {
+    struct proc *curproc = myproc();
+    struct thread *curthread = mythread();
+    struct proc *p;
+    struct thread *t;
+    int fd;
+    struct mutex* m;
+
+    if (curproc == initproc)
+        panic("init exiting");
 
-  if(curproc == initproc)
-    panic("init exiting");
+    acquire(&ptable.lock);
+    for (t = curproc->ttable; t < &(curproc->ttable[NTHREAD]); t++) {
+        if (t->tid != curthread->tid)
+            t->shouldDie = 1;
+        if (t->state == T_SLEEPING)
+            t->state = T_RUNNABLE;
+    }
+    release(&ptable.lock);
+    int numthread = 1000;
+    while (numthread > 1) {
+        numthread = 0;
+        for (t = curproc->ttable; t < &(curproc->ttable[NTHREAD]); t++) {
+            if (t->state == T_ZOMBIE) {
+                kfree(t->kstack);
+                t->kstack = 0;
+                t->tid = 0;
+                t->state = T_UNUSED;
+                curproc->numOfthread--;
+            } else {
+                if (t->state != T_UNUSED)
+                    numthread++;
+            }
+        }
+    }
 
-  // Close all open files.
-  for(fd = 0; fd < NOFILE; fd++){
-    if(curproc->ofile[fd]){
-      fileclose(curproc->ofile[fd]);
-      curproc->ofile[fd] = 0;
+    for(m=mtable.mutex;m<&(mtable.mutex[MAX_MUTEXES]);m++){
+        if(m->pid_holder==curproc->pid)
+            kthread_mutex_dealloc(m->mid);
     }
-  }
 
-  begin_op();
-  iput(curproc->cwd);
-  end_op();
-  curproc->cwd = 0;
 
-  acquire(&ptable.lock);
+    // Close all open files.
+    for (fd = 0; fd < NOFILE; fd++) {
+        if (curproc->ofile[fd]) {
+            fileclose(curproc->ofile[fd]);
+            curproc->ofile[fd] = 0;
+        }
+    }
+
+    begin_op();
+    iput(curproc->cwd);
+    end_op();
+    curproc->cwd = 0;
 
-  // Parent might be sleeping in wait().
-  wakeup1(curproc->parent);
+    acquire(&ptable.lock);
 
-  // Pass abandoned children to init.
-  for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
-    if(p->parent == curproc){
-      p->parent = initproc;
-      if(p->state == ZOMBIE)
-        wakeup1(initproc);
+    // Parent might be sleeping in wait().
+    for (t = curproc->parent->ttable; t < &curproc->parent->ttable[NTHREAD]; t++)
+        wakeup1(t);
+
+    // Pass abandoned children to init.
+    for (p = ptable.proc; p < &ptable.proc[NPROC]; p++) {
+        if (p->parent == curproc) {
+            p->parent = initproc;
+            if (p->state == ZOMBIE) {
+                for (t = initproc->ttable; t < &initproc->ttable[NTHREAD]; t++)
+                    wakeup1(t);
+            }
+        }
     }
-  }
 
-  // Jump into the scheduler, never to return.
-  curproc->state = ZOMBIE;
-  sched();
-  panic("zombie exit");
+    // Jump into the scheduler, never to return.
+    curproc->state = ZOMBIE;
+    for (t = curproc->ttable; t < &curproc->ttable[NTHREAD]; t++)
+        if (t->state != T_UNUSED)
+            t->state = T_ZOMBIE;
+
+    sched();
+    panic("zombie exit");
+}
+
+void exitThread(void) {
+    struct thread *t;
+    acquire(&ptable.lock);
+    for (t = myproc()->ttable; t < &(myproc()->ttable[NTHREAD]); t++) {
+        wakeup1(mythread());
+    }
+    mythread()->shouldDie = 0;
+    mythread()->state = T_ZOMBIE;
+    sched();
+    panic("exitThread exit");
 }
 
 // Wait for a child process to exit and return its pid.
 // Return -1 if this process has no children.
 int
-wait(void)
-{
-  struct proc *p;
-  int havekids, pid;
-  struct proc *curproc = myproc();
-  
-  acquire(&ptable.lock);
-  for(;;){
-    // Scan through table looking for exited children.
-    havekids = 0;
-    for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
-      if(p->parent != curproc)
-        continue;
-      havekids = 1;
-      if(p->state == ZOMBIE){
-        // Found one.
-        pid = p->pid;
-        kfree(p->kstack);
-        p->kstack = 0;
-        freevm(p->pgdir);
-        p->pid = 0;
-        p->parent = 0;
-        p->name[0] = 0;
-        p->killed = 0;
-        p->state = UNUSED;
-        release(&ptable.lock);
-        return pid;
-      }
-    }
+wait(void) {
+    struct proc *p;
+    int havekids, pid;
+    struct proc *curproc = myproc();
+    struct thread *curthread = mythread();
+    struct thread *t;
 
-    // No point waiting if we don't have any children.
-    if(!havekids || curproc->killed){
-      release(&ptable.lock);
-      return -1;
+    acquire(&ptable.lock);
+    for (;;) {
+        // Scan through table looking for exited children.
+        havekids = 0;
+        for (p = ptable.proc; p < &ptable.proc[NPROC]; p++) {
+            if (p->parent != curproc)
+                continue;
+            havekids = 1;
+            if (p->state == ZOMBIE) {
+                for (t = p->ttable; t < &(p->ttable[NTHREAD]); t++) {
+                    if (t->state == T_ZOMBIE) {
+                        kfree(t->kstack);
+                        t->kstack = 0;
+                        t->tid = 0;
+                        t->state = T_UNUSED;
+                    }
+                }
+                // Found one.
+                pid = p->pid;
+                freevm(p->pgdir);
+                p->pid = 0;
+                p->parent = 0;
+                p->name[0] = 0;
+                p->killed = 0;
+                p->state = UNUSED;
+                release(&ptable.lock);
+                return pid;
+            }
+        }
+
+        // No point waiting if we don't have any children.
+        if (!havekids || curproc->killed) {
+            release(&ptable.lock);
+            return -1;
+        }
+
+        // Wait for children to exit.  (See wakeup1 call in proc_exit.)
+        sleep(curthread, &ptable.lock);  //DOC: wait-sleep
     }
-
-    // Wait for children to exit.  (See wakeup1 call in proc_exit.)
-    sleep(curproc, &ptable.lock);  //DOC: wait-sleep
-  }
 }
 
 //PAGEBREAK: 42
@@ -320,39 +492,43 @@ wait(void)
 //  - eventually that process transfers control
 //      via swtch back to the scheduler.
 void
-scheduler(void)
-{
-  struct proc *p;
-  struct cpu *c = mycpu();
-  c->proc = 0;
-  
-  for(;;){
-    // Enable interrupts on this processor.
-    sti();
-
-    // Loop over process table looking for process to run.
-    acquire(&ptable.lock);
-    for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
-      if(p->state != RUNNABLE)
-        continue;
-
-      // Switch to chosen process.  It is the process's job
-      // to release ptable.lock and then reacquire it
-      // before jumping back to us.
-      c->proc = p;
-      switchuvm(p);
-      p->state = RUNNING;
-
-      swtch(&(c->scheduler), p->context);
-      switchkvm();
+scheduler(void) {
+    struct proc *p;
+    struct cpu *c = mycpu();
+    c->proc = 0;
+    struct thread *t;
+
+    for (;;) {
+        // Enable interrupts on this processor.
+        sti();
+
+        // Loop over process table looking for process to run.
+        acquire(&ptable.lock);
+        for (p = ptable.proc; p < &ptable.proc[NPROC]; p++) {
+            for (t = p->ttable; t < &(p->ttable[NTHREAD]); t++) {
+                if (t->state != T_RUNNABLE)
+                    continue;
+                // Switch to chosen process.  It is the process's job
+                // to release ptable.lock and then reacquire it
+                // before jumping back to us.
+                c->proc = p;
+                c->thread = t;
+                switchuvm(t, p);
+                p->state = USED;
+                t->state = T_RUNNING;
+
+                swtch(&(c->scheduler), t->context);
+                switchkvm();
+
+                // Process is done running for now.
+                // It should have changed its p->state before coming back.
+                c->proc = 0;
+                c->thread = 0;
+            }
+        }
+        release(&ptable.lock);
 
-      // Process is done running for now.
-      // It should have changed its p->state before coming back.
-      c->proc = 0;
     }
-    release(&ptable.lock);
-
-  }
 }
 
 // Enter scheduler.  Must hold only ptable.lock
@@ -363,137 +539,147 @@ scheduler(void)
 // break in the few places where a lock is held but
 // there's no process.
 void
-sched(void)
-{
-  int intena;
-  struct proc *p = myproc();
-
-  if(!holding(&ptable.lock))
-    panic("sched ptable.lock");
-  if(mycpu()->ncli != 1)
-    panic("sched locks");
-  if(p->state == RUNNING)
-    panic("sched running");
-  if(readeflags()&FL_IF)
-    panic("sched interruptible");
-  intena = mycpu()->intena;
-  swtch(&p->context, mycpu()->scheduler);
-  mycpu()->intena = intena;
+sched(void) {
+    int intena;
+    if (!holding(&ptable.lock))
+        panic("sched ptable.lock");
+    if (mycpu()->ncli != 1)
+        panic("sched locks");
+    if (mythread()->state == T_RUNNING)
+        panic("sched running curthread");
+    if (readeflags() & FL_IF)
+        panic("sched interruptible");
+    intena = mycpu()->intena;
+    swtch(&mythread()->context, mycpu()->scheduler);
+    mycpu()->intena = intena;
 }
 
 // Give up the CPU for one scheduling round.
 void
-yield(void)
-{
-  acquire(&ptable.lock);  //DOC: yieldlock
-  myproc()->state = RUNNABLE;
-  sched();
-  release(&ptable.lock);
+yield(void) {
+    acquire(&ptable.lock);  //DOC: yieldlock
+    myproc()->state = USED;
+    mythread()->state = T_RUNNABLE;
+    sched();
+    release(&ptable.lock);
 }
 
 // A fork child's very first scheduling by scheduler()
 // will swtch here.  "Return" to user space.
 void
-forkret(void)
-{
-  static int first = 1;
-  // Still holding ptable.lock from scheduler.
-  release(&ptable.lock);
+forkret(void) {
+    static int first = 1;
+    // Still holding ptable.lock from scheduler.
+    release(&ptable.lock);
 
-  if (first) {
-    // Some initialization functions must be run in the context
-    // of a regular process (e.g., they call sleep), and thus cannot
-    // be run from main().
-    first = 0;
-    iinit(ROOTDEV);
-    initlog(ROOTDEV);
-  }
+    if (first) {
+        // Some initialization functions must be run in the context
+        // of a regular process (e.g., they call sleep), and thus cannot
+        // be run from main().
+        first = 0;
+        iinit(ROOTDEV);
+        initlog(ROOTDEV);
+    }
 
-  // Return to "caller", actually trapret (see allocproc).
+    // Return to "caller", actually trapret (see allocproc).
 }
 
 // Atomically release lock and sleep on chan.
 // Reacquires lock when awakened.
 void
-sleep(void *chan, struct spinlock *lk)
-{
-  struct proc *p = myproc();
-  
-  if(p == 0)
-    panic("sleep");
-
-  if(lk == 0)
-    panic("sleep without lk");
-
-  // Must acquire ptable.lock in order to
-  // change p->state and then call sched.
-  // Once we hold ptable.lock, we can be
-  // guaranteed that we won't miss any wakeup
-  // (wakeup runs with ptable.lock locked),
-  // so it's okay to release lk.
-  if(lk != &ptable.lock){  //DOC: sleeplock0
-    acquire(&ptable.lock);  //DOC: sleeplock1
-    release(lk);
-  }
-  // Go to sleep.
-  p->chan = chan;
-  p->state = SLEEPING;
-
-  sched();
-
-  // Tidy up.
-  p->chan = 0;
-
-  // Reacquire original lock.
-  if(lk != &ptable.lock){  //DOC: sleeplock2
-    release(&ptable.lock);
-    acquire(lk);
-  }
+sleep(void *chan, struct spinlock *lk) {
+    struct proc *p = myproc();
+    struct thread *t = mythread();
+
+    if (p == 0)
+        panic("sleep");
+    if (t == 0)
+        panic("sleep");
+
+    if (lk == 0)
+        panic("sleep without lk");
+
+    // Must acquire ptable.lock in order to
+    // change p->state and then call sched.
+    // Once we hold ptable.lock, we can be
+    // guaranteed that we won't miss any wakeup
+    // (wakeup runs with ptable.lock locked),
+    // so it's okay to release lk.
+    if (lk != &ptable.lock) {  //DOC: sleeplock0
+        acquire(&ptable.lock);  //DOC: sleeplock1
+        release(lk);
+    }
+    // Go to sleep.
+    t->chan = chan;
+    t->state = T_SLEEPING;
+
+    sched();
+
+    if(t->shouldDie){
+        release(&ptable.lock);
+        kthread_exit();
+
+    }
+    // Tidy up.
+    t->chan = 0;
+
+    // Reacquire original lock.
+    if (lk != &ptable.lock) {  //DOC: sleeplock2
+        release(&ptable.lock);
+        acquire(lk);
+    }
 }
 
 //PAGEBREAK!
 // Wake up all processes sleeping on chan.
 // The ptable lock must be held.
 static void
-wakeup1(void *chan)
-{
-  struct proc *p;
+wakeup1(void *chan) {
+    struct proc *p;
+    struct thread *t;
+
+    for (p = ptable.proc; p < &ptable.proc[NPROC]; p++) {
+        for (t = p->ttable; t < &(p->ttable[NTHREAD]); t++) {
+            if (t->state == T_SLEEPING && t->chan == chan) {
+                p->state = USED;
+                t->state = T_RUNNABLE;
+            }
+        }
+    }
 
-  for(p = ptable.proc; p < &ptable.proc[NPROC]; p++)
-    if(p->state == SLEEPING && p->chan == chan)
-      p->state = RUNNABLE;
 }
 
 // Wake up all processes sleeping on chan.
 void
-wakeup(void *chan)
-{
-  acquire(&ptable.lock);
-  wakeup1(chan);
-  release(&ptable.lock);
+wakeup(void *chan) {
+    acquire(&ptable.lock);
+    wakeup1(chan);
+    release(&ptable.lock);
 }
 
 // Kill the process with the given pid.
 // Process won't exit until it returns
 // to user space (see trap in trap.c).
 int
-kill(int pid)
-{
-  struct proc *p;
+kill(int pid) {
+    struct proc *p;
+    struct thread *t;
 
-  acquire(&ptable.lock);
-  for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
-    if(p->pid == pid){
-      p->killed = 1;
-      // Wake process from sleep if necessary.
-      if(p->state == SLEEPING)
-        p->state = RUNNABLE;
-      release(&ptable.lock);
-      return 0;
+    acquire(&ptable.lock);
+    for (p = ptable.proc; p < &ptable.proc[NPROC]; p++) {
+        if (p->pid == pid) {
+            p->killed = 1;
+            // Wake process from sleep if necessary.
+            for (t = p->ttable; t < &(p->ttable[NTHREAD]); t++) {
+                if (t->state == T_SLEEPING)
+                    t->state = T_RUNNABLE;
+            }
+            release(&ptable.lock);
+            return 0;
+        }
     }
-  }
-  release(&ptable.lock);
-  return -1;
+    release(&ptable.lock);
+    return -1;
 }
 
 //PAGEBREAK: 36
@@ -501,34 +687,247 @@ kill(int pid)
 // Runs when user types ^P on console.
 // No lock to avoid wedging a stuck machine further.
 void
-procdump(void)
-{
-  static char *states[] = {
-  [UNUSED]    "unused",
-  [EMBRYO]    "embryo",
-  [SLEEPING]  "sleep ",
-  [RUNNABLE]  "runble",
-  [RUNNING]   "run   ",
-  [ZOMBIE]    "zombie"
-  };
-  int i;
-  struct proc *p;
-  char *state;
-  uint pc[10];
-
-  for(p = ptable.proc; p < &ptable.proc[NPROC]; p++){
-    if(p->state == UNUSED)
-      continue;
-    if(p->state >= 0 && p->state < NELEM(states) && states[p->state])
-      state = states[p->state];
-    else
-      state = "???";
-    cprintf("%d %s %s", p->pid, state, p->name);
-    if(p->state == SLEEPING){
-      getcallerpcs((uint*)p->context->ebp+2, pc);
-      for(i=0; i<10 && pc[i] != 0; i++)
-        cprintf(" %p", pc[i]);
-    }
-    cprintf("\n");
-  }
+procdump(void) {
+    static char *states[] = {
+            [T_UNUSED]    "t_unused",
+            [T_EMBRYO]    "t_embryo",
+            [T_SLEEPING]  "t_sleep ",
+            [T_RUNNABLE]  "t_runble",
+            [T_RUNNING]   "t_run   ",
+            [T_ZOMBIE]    "t_zombie"
+    };
+    int i;
+    struct proc *p;
+    struct thread *t;
+    char *state;
+    uint pc[10];
+
+    for (p = ptable.proc; p < &ptable.proc[NPROC]; p++) {
+        if (p->state == UNUSED)
+            continue;
+        for (t = p->ttable; t < &(p->ttable[NTHREAD]); t++) {
+            if (t->state >= 0 && t->state < NELEM(states) && states[t->state])
+                state = states[t->state];
+            else
+                state = "???";
+            cprintf("%d %s %s", t->tid, state, t->name);
+            if (t->state == T_SLEEPING) {
+                getcallerpcs((uint *) t->context->ebp + 2, pc);
+                for (i = 0; i < 10 && pc[i] != 0; i++)
+                    cprintf(" %p", pc[i]);
+            }
+            cprintf("\n");
+        }
+
+    }
+}
+
+int kthread_create(void (*start_func)(), void *stack) {
+    struct thread *t;
+    struct thread *curthread = mythread();
+
+    if (curthread == 0 || start_func <= 0 || stack <= 0) {
+        return -1;
+    }
+    if ((t = allocthread(myproc())) == 0) {
+        return -1;
+    }
+    acquire(&ptable.lock);
+
+    safestrcpy(t->name, "thread", sizeof("thread"));
+    *t->tf = *curthread->tf;
+    t->tf->esp = (uint) (stack);
+    t->tf->eip = (uint) start_func;
+
+    t->state = T_RUNNABLE;
+    release(&ptable.lock);
+
+    return t->tid;
+
+
+}
+
+int kthread_id() {
+    if (mythread() == 0)
+        return -1;
+    return mythread()->tid;
+}
+
+void kthread_exit() {
+    struct thread *t;
+    struct thread *curthread = mythread();
+    struct proc *curproc = myproc();
+    for (t = curproc->ttable; t < &(curproc->ttable[NTHREAD]); t++) {
+        if (curthread->tid != t->tid && (t->state != T_ZOMBIE && t->state != T_UNUSED))
+            goto found;
+    }
+    exit();
+    found:
+    exitThread();
+}
+
+int kthread_join(int thread_id) {
+    struct thread *t;
+    struct proc *p;
+
+    acquire(&ptable.lock);
+    for (;;) {
+        if(mythread()->shouldDie){
+            release(&ptable.lock);
+            kthread_exit();
+
+        }
+        for (p = ptable.proc; p < &ptable.proc[NPROC]; p++) {
+            if (p->state == UNUSED)
+                continue;
+            for (t = p->ttable; t < &(p->ttable[NTHREAD]); t++) {
+                if (t->tid == thread_id)
+                    goto found;
+            }
+
+        }
+        release(&ptable.lock);
+        return -1;
+
+        found:
+        if (t->state == T_UNUSED)
+            panic("kthread_join-thread unused is necessary");
+        if (t->state == T_ZOMBIE) {
+            release(&ptable.lock);
+            kfree(t->kstack);
+            t->kstack = 0;
+            t->tid = 0;
+            t->shouldDie = 0;
+            t->state = T_UNUSED;
+            return 0;
+        } else {
+            // Wait for children to exit.  (See wakeup1 call in proc_exit.)
+            sleep(t, &ptable.lock);  //DOC: wait-sleep
+        }
+    }
+}
+
+int kthread_mutex_alloc() {
+    int i;
+    acquire(&mtable.lock);
+    for (i = 0; i < MAX_MUTEXES; i++) {
+        if (mtable.mutex[i].state == UNINITIALIZED)
+            goto found;
+    }
+    release(&mtable.lock);
+    return -1;
+
+    found:
+    acquire(&mtable.mutex[i].mutexLock);
+    release(&mtable.lock);
+    mtable.mutex[i].lock = 0;
+    mtable.mutex[i].mid = nextmid++;
+    mtable.mutex[i].pid_holder=myproc()->pid;
+    mtable.mutex[i].numOfWaiting = 0;
+    mtable.mutex[i].state = OPEN;
+    mtable.mutex[i].holding = 0;
+    release(&mtable.mutex[i].mutexLock);
+    return mtable.mutex[i].mid;
+}
+
+int kthread_mutex_dealloc(int mutex_id) {
+    int i;
+    struct mutex *m;
+    acquire(&mtable.lock);
+    for (i = 0; i < MAX_MUTEXES; i++) {
+        if (mtable.mutex[i].mid == mutex_id)
+            goto found;
+    }
+    release(&mtable.lock);
+    return -1;
+
+    found:
+    m = &(mtable.mutex[i]);
+    if (m == 0 || m->state == CLOSE || m->numOfWaiting != 0) {
+        release(&mtable.lock);
+        return -1;
+    }
+    acquire(&m->mutexLock);
+    m->holding = 0;
+    m->mid = 0;
+    m->lock = 0;
+    m->numOfWaiting = 0;
+    mtable.mutex[i].pid_holder=0;
+    m->state = UNINITIALIZED;
+    release(&m->mutexLock);
+    release(&mtable.lock);
+    return 0;
+}
+
+
+int kthread_mutex_lock(int mutex_id) {
+    int i;
+    struct mutex *m;
+    acquire(&mtable.lock);
+    for (i = 0; i < MAX_MUTEXES; i++) {
+        if (mtable.mutex[i].mid == mutex_id)
+            goto found;
+    }
+    release(&mtable.lock);
+    return -1;
+
+    found:
+    m = &(mtable.mutex[i]);
+    if (m == 0 || m->state == UNINITIALIZED || m->holding->tid == mythread()->tid) {
+        release(&mtable.lock);
+        return -1;
+    }
+    acquire(&m->mutexLock);
+    release(&mtable.lock);
+    while (xchg((uint *) &m->lock, 1) != 0) {
+        sleep(m, &m->mutexLock);
+    }
+    m->state = CLOSE;
+    m->holding = mythread();
+    release(&m->mutexLock);
+    return 0;
+}
+
+
+int kthread_mutex_unlock(int mutex_id) {
+    int i;
+    struct mutex *m;
+    struct proc *curproc = myproc();
+    struct thread *t;
+    acquire(&mtable.lock);
+    for (i = 0; i < MAX_MUTEXES; i++) {
+        if (mtable.mutex[i].mid == mutex_id)
+            goto found;
+    }
+    release(&mtable.lock);
+    return -1;
+
+    found:
+    m = &(mtable.mutex[i]);
+    acquire(&m->mutexLock);
+    release(&mtable.lock);
+    if (m == 0 || m->state != CLOSE || m->holding->tid != mythread()->tid) {
+        release(&m->mutexLock);
+        return -1;
+    }
+    m->lock = 0;
+    m->state=OPEN;
+    m->holding=0;
+    for (t = curproc->ttable; t < &(curproc->ttable[NTHREAD]); t++) {
+        if (t->state == T_SLEEPING && t->chan == m) {
+            t->state = T_RUNNABLE;
+            release(&m->mutexLock);
+            return 0;
+        }
+    }
+    release(&m->mutexLock);
+    return 0;
 }
+
+
+
+
+
+
+
+
diff --git a/proc.h b/proc.h
index 1647114..44f542d 100644
--- a/proc.h
+++ b/proc.h
@@ -1,13 +1,14 @@
 // Per-CPU state
 struct cpu {
-  uchar apicid;                // Local APIC ID
-  struct context *scheduler;   // swtch() here to enter scheduler
-  struct taskstate ts;         // Used by x86 to find stack for interrupt
-  struct segdesc gdt[NSEGS];   // x86 global descriptor table
-  volatile uint started;       // Has the CPU started?
-  int ncli;                    // Depth of pushcli nesting.
-  int intena;                  // Were interrupts enabled before pushcli?
-  struct proc *proc;           // The process running on this cpu or null
+    uchar apicid;                // Local APIC ID
+    struct context *scheduler;   // swtch() here to enter scheduler
+    struct taskstate ts;         // Used by x86 to find stack for interrupt
+    struct segdesc gdt[NSEGS];   // x86 global descriptor table
+    volatile uint started;       // Has the CPU started?
+    int ncli;                    // Depth of pushcli nesting.
+    int intena;                  // Were interrupts enabled before pushcli?
+    struct proc *proc;           // The process running on this cpu or null
+    struct thread *thread;       // The thread running on this cpu or null
 };
 
 extern struct cpu cpus[NCPU];
@@ -25,30 +26,50 @@ extern int ncpu;
 // at the "Switch stacks" comment. Switch doesn't save eip explicitly,
 // but it is on the stack and allocproc() manipulates it.
 struct context {
-  uint edi;
-  uint esi;
-  uint ebx;
-  uint ebp;
-  uint eip;
+    uint edi;
+    uint esi;
+    uint ebx;
+    uint ebp;
+    uint eip;
 };
 
-enum procstate { UNUSED, EMBRYO, SLEEPING, RUNNABLE, RUNNING, ZOMBIE };
+enum threadstate {
+    T_UNUSED, T_EMBRYO, T_SLEEPING, T_RUNNABLE, T_RUNNING, T_ZOMBIE
+};
+
+enum procstate {
+    UNUSED, USED, ZOMBIE
+};
+
+
+struct thread{
+    char *kstack;                // Bottom of kernel stack for this process
+    enum threadstate state;      // Process state
+    struct trapframe *tf;        // Trap frame for current syscall
+    int tid;		             // thread ID
+    struct proc *parent;         // Parent process
+    struct context *context;     // swtch() here to run thread
+    void *chan;                  // If non-zero, sleeping on chan
+    int shouldDie;               // If non- zero , Thread need to be exit
+    struct thread* next_thread;  // next thread that wait in mutex
+    int mutex_flag;              // the mutex lock move to you;
+    char name[16];               // thread name (debugging)
+
+};
 
 // Per-process state
 struct proc {
-  uint sz;                     // Size of process memory (bytes)
-  pde_t* pgdir;                // Page table
-  char *kstack;                // Bottom of kernel stack for this process
-  enum procstate state;        // Process state
-  int pid;                     // Process ID
-  struct proc *parent;         // Parent process
-  struct trapframe *tf;        // Trap frame for current syscall
-  struct context *context;     // swtch() here to run process
-  void *chan;                  // If non-zero, sleeping on chan
-  int killed;                  // If non-zero, have been killed
-  struct file *ofile[NOFILE];  // Open files
-  struct inode *cwd;           // Current directory
-  char name[16];               // Process name (debugging)
+    uint sz;                        // Size of process memory (bytes)
+    pde_t *pgdir;                   // Page table
+    enum procstate state;           // Process state
+    int pid;                        // Process ID
+    struct proc *parent;            // Parent process
+    int killed;                     // If non-zero, have been killed
+    struct file *ofile[NOFILE];     // Open files
+    struct inode *cwd;              // Current directory
+    struct thread ttable[NTHREAD];  //thread table
+    char name[16];                  // Process name (debugging)
+    int numOfthread;                //
 };
 
 // Process memory is laid out contiguously, low addresses first:
diff --git a/sanity.c b/sanity.c
new file mode 100644
index 0000000..5e07ad7
--- /dev/null
+++ b/sanity.c
@@ -0,0 +1,188 @@
+#include "types.h"
+#include "stat.h"
+#include "user.h"
+#include "tournament_tree.h"
+
+void ThreadTest();
+
+void MutexTest();
+
+void tournamentTreeTest();
+
+int global;
+int mutex_id;
+int lock;
+trnmnt_tree *tree;
+int openShot;
+int cs = 0;
+
+int main(int argc, char *argv[]) {
+    int pid;
+    if ((pid = fork()) == 0) {
+        ThreadTest();
+    } else {
+        if (pid < 0) {
+            printf(1, "Fork failed for thread test");
+        } else {
+            wait();
+        }
+
+    }
+
+
+    if ((pid = fork()) == 0) {
+        MutexTest();
+    } else {
+        if (pid < 0) {
+            printf(1, "Fork failed for mutex test");
+        } else {
+            wait();
+        }
+
+    }
+
+    if ((pid = fork()) == 0) {
+        tournamentTreeTest();
+    } else {
+        if (pid < 0) {
+            printf(1, "Fork failed for Tournament Tree test");
+        } else {
+            wait();
+        }
+
+    }
+    exit();
+}
+
+void foo(void) {
+    global = 1;
+    kthread_exit();
+}
+
+void ThreadTest() {
+    int first;
+    void *firstStack = ((char *) malloc(500 * sizeof(char))) + 500;
+    global = 0;
+    first = kthread_create(foo, firstStack);
+    if (kthread_join(first) == -1 || !global) {
+        printf(1, "Waiting failed.\n");
+        printf(1, "test thread  failed\n");
+        kthread_exit();
+    } else {
+        printf(1, "Test thread  success\n");
+    }
+
+    free(firstStack);
+
+    global = 0;
+
+    exit();
+}
+
+void goo(void) {
+    int result = kthread_mutex_lock(mutex_id);
+    if (result < 0) {
+        printf(1, "problem with mutex lock\n");
+        kthread_exit();
+    }
+    int unlock = kthread_mutex_unlock(mutex_id);
+    if (unlock < 0) {
+        printf(1, "problem with mutex unlock\n");
+        kthread_exit();
+    }
+    global++;
+    kthread_exit();
+}
+
+void MutexTest() {
+    int first, second, third;
+    void *firstStack = ((char *) malloc(500 * sizeof(char))) + 500;
+    void *secondStack = ((char *) malloc(500 * sizeof(char))) + 500;
+    void *thirdStack = ((char *) malloc(500 * sizeof(char))) + 500;
+
+    global = 0;
+    first = kthread_create(goo, firstStack);
+    second = kthread_create(goo, secondStack);
+    third = kthread_create(goo, thirdStack);
+
+    if ((mutex_id = kthread_mutex_alloc()) == -1) {
+        printf(1, "mutex allocated failed\n");
+        kthread_exit();
+    }
+
+
+    if (kthread_join(first) == -1 || kthread_join(second) == -1 || kthread_join(third) == -1 || global != 3) {
+        printf(1, "test mutex failed and global = %d.\n", global);
+        kthread_exit();
+    } else {
+        printf(1, "Test mutex success.\n");
+    }
+    kthread_mutex_dealloc(mutex_id);
+
+    global = 0;
+    exit();
+}
+
+void koo1() {
+    while (openShot);
+
+    if (trnmnt_tree_acquire(tree, 0) < 0) {
+        printf(1, "trnmnt_tree locked unsuccessfully\n");
+    }
+
+    cs = 1;
+    sleep(400);
+
+    if (cs != 1) {
+        printf(1, "mutual exclusion failed by %d\n", cs);
+    }
+
+    if (trnmnt_tree_release(tree, 0) < 0) {
+        printf(1, "trnmnt_tree unlocked unsuccessfully\n");
+    }
+
+    kthread_exit();
+}
+
+void koo2() {
+    while (openShot);
+    sleep(200);
+
+    if (trnmnt_tree_acquire(tree, 1) < 0) {
+        printf(1, "trnmnt_tree locked unsuccessfully\n");
+    }
+    cs = -1;
+    if (trnmnt_tree_release(tree, 1) < 0) {
+        printf(1, "trnmnt_tree unlocked unsuccessfully\n");
+    }
+    kthread_exit();
+}
+
+void tournamentTreeTest() {
+    openShot = 1;
+    int first, second;
+
+    void *firstStack = ((char *) malloc(500 * sizeof(char))) + 500;
+    void *secondStack = ((char *) malloc(500 * sizeof(char))) + 500;
+
+    if ((tree = trnmnt_tree_alloc(1)) == 0) {
+        printf(1, "trnmnt_tree allocated unsuccessfully\n");
+    }
+    first = kthread_create(koo1, firstStack);
+    second = kthread_create(koo2, secondStack);
+
+    openShot = 0;
+
+    if (kthread_join(first) == -1 || kthread_join(second) == -1 || cs != -1) {
+        printf(1, "Test tournamentTreeTest failed\n");
+
+    } else {
+        printf(1, "Test tournamentTreeTest success\n");
+    }
+
+    if (trnmnt_tree_dealloc(tree) == -1) {
+        printf(1, "trnmnt_tree deallocated unsuccessfully\n");
+    }
+    exit();
+}
+
diff --git a/syscall.c b/syscall.c
index ee85261..77d7245 100644
--- a/syscall.c
+++ b/syscall.c
@@ -15,58 +15,54 @@
 
 // Fetch the int at addr from the current process.
 int
-fetchint(uint addr, int *ip)
-{
-  struct proc *curproc = myproc();
+fetchint(uint addr, int *ip) {
+    struct proc *curproc = myproc();
 
-  if(addr >= curproc->sz || addr+4 > curproc->sz)
-    return -1;
-  *ip = *(int*)(addr);
-  return 0;
+    if (addr >= curproc->sz || addr + 4 > curproc->sz)
+        return -1;
+    *ip = *(int *) (addr);
+    return 0;
 }
 
 // Fetch the nul-terminated string at addr from the current process.
 // Doesn't actually copy the string - just sets *pp to point at it.
 // Returns length of string, not including nul.
 int
-fetchstr(uint addr, char **pp)
-{
-  char *s, *ep;
-  struct proc *curproc = myproc();
+fetchstr(uint addr, char **pp) {
+    char *s, *ep;
+    struct proc *curproc = myproc();
 
-  if(addr >= curproc->sz)
+    if (addr >= curproc->sz)
+        return -1;
+    *pp = (char *) addr;
+    ep = (char *) curproc->sz;
+    for (s = *pp; s < ep; s++) {
+        if (*s == 0)
+            return s - *pp;
+    }
     return -1;
-  *pp = (char*)addr;
-  ep = (char*)curproc->sz;
-  for(s = *pp; s < ep; s++){
-    if(*s == 0)
-      return s - *pp;
-  }
-  return -1;
 }
 
 // Fetch the nth 32-bit system call argument.
 int
-argint(int n, int *ip)
-{
-  return fetchint((myproc()->tf->esp) + 4 + 4*n, ip);
+argint(int n, int *ip) {
+    return fetchint((mythread()->tf->esp) + 4 + 4 * n, ip);
 }
 
 // Fetch the nth word-sized system call argument as a pointer
 // to a block of memory of size bytes.  Check that the pointer
 // lies within the process address space.
 int
-argptr(int n, char **pp, int size)
-{
-  int i;
-  struct proc *curproc = myproc();
- 
-  if(argint(n, &i) < 0)
-    return -1;
-  if(size < 0 || (uint)i >= curproc->sz || (uint)i+size > curproc->sz)
-    return -1;
-  *pp = (char*)i;
-  return 0;
+argptr(int n, char **pp, int size) {
+    int i;
+    struct proc *curproc = myproc();
+
+    if (argint(n, &i) < 0)
+        return -1;
+    if (size < 0 || (uint) i >= curproc->sz || (uint) i + size > curproc->sz)
+        return -1;
+    *pp = (char *) i;
+    return 0;
 }
 
 // Fetch the nth word-sized system call argument as a string pointer.
@@ -74,72 +70,117 @@ argptr(int n, char **pp, int size)
 // (There is no shared writable memory, so the string can't change
 // between this check and being used by the kernel.)
 int
-argstr(int n, char **pp)
-{
-  int addr;
-  if(argint(n, &addr) < 0)
-    return -1;
-  return fetchstr(addr, pp);
+argstr(int n, char **pp) {
+    int addr;
+    if (argint(n, &addr) < 0)
+        return -1;
+    return fetchstr(addr, pp);
 }
 
 extern int sys_chdir(void);
+
 extern int sys_close(void);
+
 extern int sys_dup(void);
+
 extern int sys_exec(void);
+
 extern int sys_exit(void);
+
 extern int sys_fork(void);
+
 extern int sys_fstat(void);
+
 extern int sys_getpid(void);
+
 extern int sys_kill(void);
+
 extern int sys_link(void);
+
 extern int sys_mkdir(void);
+
 extern int sys_mknod(void);
+
 extern int sys_open(void);
+
 extern int sys_pipe(void);
+
 extern int sys_read(void);
+
 extern int sys_sbrk(void);
+
 extern int sys_sleep(void);
+
 extern int sys_unlink(void);
+
 extern int sys_wait(void);
+
 extern int sys_write(void);
+
 extern int sys_uptime(void);
 
+extern int sys_kthread_create(void);
+
+extern int sys_kthread_id(void);
+
+extern int sys_kthread_exit();
+
+extern int sys_kthread_join(void);
+
+extern int sys_kthread_mutex_alloc(void);
+
+extern int sys_kthread_mutex_dealloc(void);
+
+extern int sys_kthread_mutex_lock(void);
+
+extern int sys_kthread_mutex_unlock(void);
+
+
 static int (*syscalls[])(void) = {
-[SYS_fork]    sys_fork,
-[SYS_exit]    sys_exit,
-[SYS_wait]    sys_wait,
-[SYS_pipe]    sys_pipe,
-[SYS_read]    sys_read,
-[SYS_kill]    sys_kill,
-[SYS_exec]    sys_exec,
-[SYS_fstat]   sys_fstat,
-[SYS_chdir]   sys_chdir,
-[SYS_dup]     sys_dup,
-[SYS_getpid]  sys_getpid,
-[SYS_sbrk]    sys_sbrk,
-[SYS_sleep]   sys_sleep,
-[SYS_uptime]  sys_uptime,
-[SYS_open]    sys_open,
-[SYS_write]   sys_write,
-[SYS_mknod]   sys_mknod,
-[SYS_unlink]  sys_unlink,
-[SYS_link]    sys_link,
-[SYS_mkdir]   sys_mkdir,
-[SYS_close]   sys_close,
+        [SYS_fork]    sys_fork,
+        [SYS_exit]    sys_exit,
+        [SYS_wait]    sys_wait,
+        [SYS_pipe]    sys_pipe,
+        [SYS_read]    sys_read,
+        [SYS_kill]    sys_kill,
+        [SYS_exec]    sys_exec,
+        [SYS_fstat]   sys_fstat,
+        [SYS_chdir]   sys_chdir,
+        [SYS_dup]     sys_dup,
+        [SYS_getpid]  sys_getpid,
+        [SYS_sbrk]    sys_sbrk,
+        [SYS_sleep]   sys_sleep,
+        [SYS_uptime]  sys_uptime,
+        [SYS_open]    sys_open,
+        [SYS_write]   sys_write,
+        [SYS_mknod]   sys_mknod,
+        [SYS_unlink]  sys_unlink,
+        [SYS_link]    sys_link,
+        [SYS_mkdir]   sys_mkdir,
+        [SYS_close]   sys_close,
+        [SYS_kthread_create]    sys_kthread_create,
+        [SYS_kthread_id]    sys_kthread_id,
+        [SYS_kthread_exit]    sys_kthread_exit,
+        [SYS_kthread_join]    sys_kthread_join,
+        [SYS_kthread_mutex_alloc]    sys_kthread_mutex_alloc,
+        [SYS_kthread_mutex_dealloc]    sys_kthread_mutex_dealloc,
+        [SYS_kthread_mutex_lock]    sys_kthread_mutex_lock,
+        [SYS_kthread_mutex_unlock]    sys_kthread_mutex_unlock,
+
+
 };
 
 void
-syscall(void)
-{
-  int num;
-  struct proc *curproc = myproc();
-
-  num = curproc->tf->eax;
-  if(num > 0 && num < NELEM(syscalls) && syscalls[num]) {
-    curproc->tf->eax = syscalls[num]();
-  } else {
-    cprintf("%d %s: unknown sys call %d\n",
-            curproc->pid, curproc->name, num);
-    curproc->tf->eax = -1;
-  }
+syscall(void) {
+    int num;
+    struct thread *curthread = mythread();
+
+    num = curthread->tf->eax;
+    if (num > 0 && num < NELEM(syscalls) && syscalls[num]) {
+        curthread->tf->eax = syscalls[num]();
+    } else {
+        cprintf("%d %s: unknown sys call %d\n",
+                curthread->tid, curthread->name, num);
+        curthread->tf->eax = -1;
+    }
 }
diff --git a/syscall.h b/syscall.h
index bc5f356..d073c65 100644
--- a/syscall.h
+++ b/syscall.h
@@ -20,3 +20,15 @@
 #define SYS_link   19
 #define SYS_mkdir  20
 #define SYS_close  21
+#define SYS_kthread_create  22
+#define SYS_kthread_id  23
+#define SYS_kthread_exit  24
+#define SYS_kthread_join  25
+#define SYS_kthread_mutex_alloc  26
+#define SYS_kthread_mutex_dealloc  27
+#define SYS_kthread_mutex_lock  28
+#define SYS_kthread_mutex_unlock  29
+
+
+
+
diff --git a/sysproc.c b/sysproc.c
index 0686d29..61cb667 100644
--- a/sysproc.c
+++ b/sysproc.c
@@ -8,84 +8,145 @@
 #include "proc.h"
 
 int
-sys_fork(void)
-{
-  return fork();
+sys_fork(void) {
+    return fork();
 }
 
 int
-sys_exit(void)
-{
-  exit();
-  return 0;  // not reached
+sys_exit(void) {
+    exit();
+    return 0;  // not reached
 }
 
 int
-sys_wait(void)
-{
-  return wait();
+sys_wait(void) {
+    return wait();
 }
 
 int
-sys_kill(void)
-{
-  int pid;
+sys_kill(void) {
+    int pid;
 
-  if(argint(0, &pid) < 0)
-    return -1;
-  return kill(pid);
+    if (argint(0, &pid) < 0)
+        return -1;
+    return kill(pid);
 }
 
 int
-sys_getpid(void)
-{
-  return myproc()->pid;
+sys_getpid(void) {
+    return myproc()->pid;
 }
 
 int
-sys_sbrk(void)
-{
-  int addr;
-  int n;
+sys_sbrk(void) {
+    int addr;
+    int n;
 
-  if(argint(0, &n) < 0)
-    return -1;
-  addr = myproc()->sz;
-  if(growproc(n) < 0)
-    return -1;
-  return addr;
+    if (argint(0, &n) < 0)
+        return -1;
+    addr = myproc()->sz;
+    if (growproc(n) < 0)
+        return -1;
+    return addr;
 }
 
 int
-sys_sleep(void)
-{
-  int n;
-  uint ticks0;
-
-  if(argint(0, &n) < 0)
-    return -1;
-  acquire(&tickslock);
-  ticks0 = ticks;
-  while(ticks - ticks0 < n){
-    if(myproc()->killed){
-      release(&tickslock);
-      return -1;
+sys_sleep(void) {
+    int n;
+    uint ticks0;
+
+    if (argint(0, &n) < 0)
+        return -1;
+    acquire(&tickslock);
+    ticks0 = ticks;
+    while (ticks - ticks0 < n) {
+        if (myproc()->killed) {
+            release(&tickslock);
+            return -1;
+        }
+        sleep(&ticks, &tickslock);
     }
-    sleep(&ticks, &tickslock);
-  }
-  release(&tickslock);
-  return 0;
+    release(&tickslock);
+    return 0;
 }
 
 // return how many clock tick interrupts have occurred
 // since start.
 int
-sys_uptime(void)
-{
-  uint xticks;
+sys_uptime(void) {
+    uint xticks;
+
+    acquire(&tickslock);
+    xticks = ticks;
+    release(&tickslock);
+    return xticks;
+}
+
+int sys_kthread_create(void) {
+
+    void (*start_func)();
+    void *stack;
+
+    if (argptr(0, (void *) &start_func, sizeof(*start_func)) < 0)
+        return -1;
+
+    if (argptr(1, (void *) &stack, sizeof(*stack)) < 0)
+        return -1;
+
+    return kthread_create(start_func, stack);
+}
 
-  acquire(&tickslock);
-  xticks = ticks;
-  release(&tickslock);
-  return xticks;
+
+int sys_kthread_id(void) {
+    return kthread_id();
+}
+
+int sys_kthread_exit(void) {
+    kthread_exit();
+    return 0;
 }
+
+int sys_kthread_join(void) {
+    int thread_id;
+
+    if (argint(0, &thread_id) < 0)
+        return -1;
+
+    return kthread_join(thread_id);
+}
+
+
+int sys_kthread_mutex_alloc(void){
+    return kthread_mutex_alloc();
+}
+
+int sys_kthread_mutex_dealloc(void){
+    int mutex_id;
+
+    if (argint(0, &mutex_id) < 0)
+        return -1;
+
+    return kthread_mutex_dealloc(mutex_id);
+}
+
+int sys_kthread_mutex_lock(void){
+    int mutex_id;
+
+    if (argint(0, &mutex_id) < 0)
+        return -1;
+
+    return kthread_mutex_lock(mutex_id);
+}
+
+int sys_kthread_mutex_unlock(void){
+    int mutex_id;
+
+    if (argint(0, &mutex_id) < 0)
+        return -1;
+
+    return kthread_mutex_unlock(mutex_id);
+}
+
+
+
+
diff --git a/tournament_tree.c b/tournament_tree.c
new file mode 100644
index 0000000..cc27475
--- /dev/null
+++ b/tournament_tree.c
@@ -0,0 +1,154 @@
+#include "types.h"
+#include "user.h"
+#include "kthread.h"
+#include "tournament_tree.h"
+
+
+int powordepth(int exp) {
+    int init = 2;
+    int output = 1;
+    while (exp != 0) {
+        output *= init;
+        exp--;
+    }
+    return output;
+}
+
+struct trnmnt_tree *trnmnt_tree_alloc(int depth) {
+    struct trnmnt_tree *output = malloc(sizeof(trnmnt_tree));
+    int i;
+    if (depth <= 0 || depth > 6)
+        return 0;
+    int treeSize = powordepth(depth) - 1;
+
+    //depth field
+    output->depth = depth;
+
+    //init lock field
+    if ((output->Lock = kthread_mutex_alloc()) == -1) {
+        free(output);
+        return 0;
+    }
+
+    //init mutextree field
+    if ((output->mutextree = malloc((treeSize * sizeof(int)))) == 0) {
+        free(output);
+        return 0;
+    }
+    for (i = 0; i < treeSize; i++){
+        output->mutextree[i] = kthread_mutex_alloc();
+
+    }
+
+    int initCheck = 0;
+    for (int i = 0; i < treeSize; i++) {
+        if (output->mutextree[i] == -1)
+            initCheck = 1;
+    }
+    if (initCheck) {
+        for (int i = 0; i < treeSize; i++) {
+            kthread_mutex_dealloc(output->mutextree[i]);
+        }
+        kthread_mutex_dealloc(output->Lock);
+        free(output->mutextree);
+        free(output);
+        return 0;
+    }
+
+
+
+    //init threadMap field
+    if ((output->threadMap = malloc(powordepth(depth) * sizeof(int))) == 0) {
+        for (int i = 0; i < treeSize; i++) {
+            kthread_mutex_dealloc(output->mutextree[i]);
+        }
+        kthread_mutex_dealloc(output->Lock);
+        free(output->mutextree);
+        free(output);
+        return 0;
+    }
+    for (i = 0; i < powordepth(depth); i++)
+        output->threadMap[i] = -1;
+
+    return output;
+}
+
+int trnmnt_tree_dealloc(struct trnmnt_tree *tree) {
+    int i;
+    kthread_mutex_lock(tree->Lock);
+    int treeSize = powordepth(tree->depth) - 1;
+    for (i = 0; i < powordepth(tree->depth); i++) {
+        if (tree->threadMap[i] != -1){
+            kthread_mutex_unlock(tree->Lock);
+            return -1;
+        }
+    }
+    for (int i = 0; i < treeSize; i++) {
+        if (kthread_mutex_dealloc(tree->mutextree[i]) == -1){
+            kthread_mutex_unlock(tree->Lock);
+            return -1;
+        }
+    }
+    kthread_mutex_unlock(tree->Lock);
+    kthread_mutex_dealloc(tree->Lock);
+    free(tree->threadMap);
+    free(tree->mutextree);
+    free(tree);
+    tree->depth = 0;
+    return 0;
+}
+
+
+int trnmnt_tree_acquire(trnmnt_tree *tree, int ID) {
+    int treePosition, fatherPosition = -1;
+    if (ID < 0 || tree == 0 || ID > (powordepth(tree->depth) - 1)) {
+        return -1;
+    }
+    kthread_mutex_lock(tree->Lock);
+
+    if (tree->threadMap[ID] != -1) {
+        kthread_mutex_unlock(tree->Lock);
+        return -1;
+    }
+    tree->threadMap[ID] = kthread_id();
+    kthread_mutex_unlock(tree->Lock);
+    treePosition = (powordepth(tree->depth) - 1) + ID;
+    fatherPosition = (treePosition - 1) / 2;
+    while (treePosition != 0) {
+        kthread_mutex_lock(tree->mutextree[fatherPosition]);
+        treePosition = fatherPosition;
+        fatherPosition = (treePosition - 1) / 2;
+    }
+    return 0;
+}
+
+int trnmnt_tree_release_rec(struct trnmnt_tree *tree, int position) {
+    int fatherPosition = (position - 1) / 2;
+    if (fatherPosition != 0){
+        if (trnmnt_tree_release_rec(tree, fatherPosition) == -1){
+            //printf(1,"position id=%d, fatherPosition=%d\n",position, fatherPosition);
+            return -1;
+        }
+    }
+    return kthread_mutex_unlock(tree->mutextree[fatherPosition]);
+}
+
+
+int trnmnt_tree_release(struct trnmnt_tree *tree, int ID) {
+    kthread_mutex_lock(tree->Lock);
+    if (tree->threadMap[ID] != kthread_id()) {
+        kthread_mutex_unlock(tree->Lock);
+        return -1;
+    }
+    if(trnmnt_tree_release_rec(tree, (powordepth(tree->depth) - 1) + ID)==-1){
+        kthread_mutex_unlock(tree->Lock);
+        return -1;
+    }
+    tree->threadMap[ID] = -1;
+    kthread_mutex_unlock(tree->Lock);
+    return 0;
+}
+
+
+
+
diff --git a/tournament_tree.h b/tournament_tree.h
new file mode 100644
index 0000000..1195a93
--- /dev/null
+++ b/tournament_tree.h
@@ -0,0 +1,16 @@
+
+
+typedef struct trnmnt_tree{
+    int Lock;
+    int* mutextree;
+    int* threadMap;
+    int depth;
+}trnmnt_tree;
+
+
+
+
+struct trnmnt_tree* trnmnt_tree_alloc(int depth);
+int trnmnt_tree_dealloc(struct trnmnt_tree* tree);
+int trnmnt_tree_acquire(struct trnmnt_tree* tree,int ID);
+int trnmnt_tree_release(struct trnmnt_tree* tree,int ID);
\ No newline at end of file
diff --git a/trap.c b/trap.c
index 41c66eb..99e9be7 100644
--- a/trap.c
+++ b/trap.c
@@ -15,98 +15,123 @@ struct spinlock tickslock;
 uint ticks;
 
 void
-tvinit(void)
-{
-  int i;
+tvinit(void) {
+    int i;
 
-  for(i = 0; i < 256; i++)
-    SETGATE(idt[i], 0, SEG_KCODE<<3, vectors[i], 0);
-  SETGATE(idt[T_SYSCALL], 1, SEG_KCODE<<3, vectors[T_SYSCALL], DPL_USER);
+    for (i = 0; i < 256; i++) SETGATE(idt[i], 0, SEG_KCODE << 3, vectors[i], 0);
+    SETGATE(idt[T_SYSCALL], 1, SEG_KCODE << 3, vectors[T_SYSCALL], DPL_USER);
 
-  initlock(&tickslock, "time");
+    initlock(&tickslock, "time");
 }
 
 void
-idtinit(void)
-{
-  lidt(idt, sizeof(idt));
+idtinit(void) {
+    lidt(idt, sizeof(idt));
 }
 
 //PAGEBREAK: 41
 void
-trap(struct trapframe *tf)
-{
-  if(tf->trapno == T_SYSCALL){
-    if(myproc()->killed)
-      exit();
-    myproc()->tf = tf;
-    syscall();
-    if(myproc()->killed)
-      exit();
-    return;
-  }
+trap(struct trapframe *tf) {
+    if (tf->trapno == T_SYSCALL) {
+        if (myproc()->killed)
+            exit();
+        if (mythread()->shouldDie) {
+//            cprintf("mythread()->shouldDie1- ");
+//            cprintState(mythread());
+//            cprintf("\n");
+            kthread_exit();
+        }
+        mythread()->tf = tf;
+        syscall();
+        if (myproc()->killed)
+            exit();
+        if (mythread()->shouldDie) {
+//            cprintf("mythread()->shouldDie2- ");
+//            cprintState(mythread());
+//            cprintf("\n");
+            kthread_exit();
+        }
+        return;
+    }
+
+    switch (tf->trapno) {
+        case T_IRQ0 + IRQ_TIMER:
+            if (cpuid() == 0) {
+                acquire(&tickslock);
+                ticks++;
+                wakeup(&ticks);
+                release(&tickslock);
+            }
+            lapiceoi();
+            break;
+        case T_IRQ0 + IRQ_IDE:
+            ideintr();
+            lapiceoi();
+            break;
+        case T_IRQ0 + IRQ_IDE + 1:
+            // Bochs generates spurious IDE1 interrupts.
+            break;
+        case T_IRQ0 + IRQ_KBD:
+            kbdintr();
+            lapiceoi();
+            break;
+        case T_IRQ0 + IRQ_COM1:
+            uartintr();
+            lapiceoi();
+            break;
+        case T_IRQ0 + 7:
+        case T_IRQ0 + IRQ_SPURIOUS:
+            cprintf("cpu%d: spurious interrupt at %x:%x\n",
+                    cpuid(), tf->cs, tf->eip);
+            lapiceoi();
+            break;
 
-  switch(tf->trapno){
-  case T_IRQ0 + IRQ_TIMER:
-    if(cpuid() == 0){
-      acquire(&tickslock);
-      ticks++;
-      wakeup(&ticks);
-      release(&tickslock);
+            //PAGEBREAK: 13
+        default:
+            if (myproc() == 0 || (tf->cs & 3) == 0) {
+                // In kernel, it must be our mistake.
+                cprintf("unexpected trap %d from cpu %d eip %x (cr2=0x%x)\n",
+                        tf->trapno, cpuid(), tf->eip, rcr2());
+                panic("trap");
+            }
+            // In user space, assume process misbehaved.
+            cprintf("pid %d %s: trap %d err %d on cpu %d "
+                            "eip 0x%x addr 0x%x--kill proc\n",
+                    myproc()->pid, myproc()->name, tf->trapno,
+                    tf->err, cpuid(), tf->eip, rcr2());
+            myproc()->killed = 1;
     }
-    lapiceoi();
-    break;
-  case T_IRQ0 + IRQ_IDE:
-    ideintr();
-    lapiceoi();
-    break;
-  case T_IRQ0 + IRQ_IDE+1:
-    // Bochs generates spurious IDE1 interrupts.
-    break;
-  case T_IRQ0 + IRQ_KBD:
-    kbdintr();
-    lapiceoi();
-    break;
-  case T_IRQ0 + IRQ_COM1:
-    uartintr();
-    lapiceoi();
-    break;
-  case T_IRQ0 + 7:
-  case T_IRQ0 + IRQ_SPURIOUS:
-    cprintf("cpu%d: spurious interrupt at %x:%x\n",
-            cpuid(), tf->cs, tf->eip);
-    lapiceoi();
-    break;
 
-  //PAGEBREAK: 13
-  default:
-    if(myproc() == 0 || (tf->cs&3) == 0){
-      // In kernel, it must be our mistake.
-      cprintf("unexpected trap %d from cpu %d eip %x (cr2=0x%x)\n",
-              tf->trapno, cpuid(), tf->eip, rcr2());
-      panic("trap");
+    // Force process exit if it has been killed and is in user space.
+    // (If it is still executing in the kernel, let it keep running
+    // until it gets to the regular system call return.)
+    if (myproc() && myproc()->killed && (tf->cs & 3) == DPL_USER)
+        exit();
+
+    if (mythread() && mythread()->shouldDie && (tf->cs & 3) == DPL_USER) {
+//        cprintf("mythread() && mythread()->shouldDie && (tf->cs&3) == DPL_USER- ");
+//        cprintState(mythread());
+//        cprintf("\n");
+        kthread_exit();
     }
-    // In user space, assume process misbehaved.
-    cprintf("pid %d %s: trap %d err %d on cpu %d "
-            "eip 0x%x addr 0x%x--kill proc\n",
-            myproc()->pid, myproc()->name, tf->trapno,
-            tf->err, cpuid(), tf->eip, rcr2());
-    myproc()->killed = 1;
-  }
 
-  // Force process exit if it has been killed and is in user space.
-  // (If it is still executing in the kernel, let it keep running
-  // until it gets to the regular system call return.)
-  if(myproc() && myproc()->killed && (tf->cs&3) == DPL_USER)
-    exit();
+    // Force process to give up CPU on clock tick.
+    // Force process to give up CPU on clock tick.
+    // If interrupts were on while locks held, would need to check nlock.
+    if (mythread() && mythread()->state == T_RUNNING &&
+        tf->trapno == T_IRQ0 + IRQ_TIMER)
+        yield();
 
-  // Force process to give up CPU on clock tick.
-  // If interrupts were on while locks held, would need to check nlock.
-  if(myproc() && myproc()->state == RUNNING &&
-     tf->trapno == T_IRQ0+IRQ_TIMER)
-    yield();
+    // Check if the process has been killed since we yielded
+    if (myproc() && myproc()->killed && (tf->cs & 3) == DPL_USER)
+        exit();
+
+    // Check if the process has been killed since we yielded
+    if (mythread() && mythread()->shouldDie && (tf->cs & 3) == DPL_USER) {
+//        cprintf("mythread() && mythread()->shouldDie && (tf->cs&3) == DPL_USER- ");
+//        cprintState(mythread());
+//        cprintf("\n");
+        kthread_exit();
+    }
 
-  // Check if the process has been killed since we yielded
-  if(myproc() && myproc()->killed && (tf->cs&3) == DPL_USER)
-    exit();
 }
diff --git a/user.h b/user.h
index 4f99c52..3b69bb3 100644
--- a/user.h
+++ b/user.h
@@ -23,6 +23,14 @@ int getpid(void);
 char* sbrk(int);
 int sleep(int);
 int uptime(void);
+int kthread_create(void (*start_func)(), void* stack);
+int kthread_id();
+void kthread_exit();
+int kthread_join(int thread_id);
+int kthread_mutex_alloc();
+int kthread_mutex_dealloc(int mutex_id);
+int kthread_mutex_lock(int mutex_id);
+int kthread_mutex_unlock(int mutex_id);
 
 // ulib.c
 int stat(const char*, struct stat*);
diff --git a/usys.S b/usys.S
index 8bfd8a1..8006886 100644
--- a/usys.S
+++ b/usys.S
@@ -29,3 +29,14 @@ SYSCALL(getpid)
 SYSCALL(sbrk)
 SYSCALL(sleep)
 SYSCALL(uptime)
+SYSCALL(kthread_create)
+SYSCALL(kthread_id)
+SYSCALL(kthread_exit)
+SYSCALL(kthread_join)
+SYSCALL(kthread_mutex_alloc)
+SYSCALL(kthread_mutex_dealloc)
+SYSCALL(kthread_mutex_lock)
+SYSCALL(kthread_mutex_unlock)
+
+
+
diff --git a/vm.c b/vm.c
index 7134cff..34d5558 100644
--- a/vm.c
+++ b/vm.c
@@ -13,70 +13,67 @@ pde_t *kpgdir;  // for use in scheduler()
 // Set up CPU's kernel segment descriptors.
 // Run once on entry on each CPU.
 void
-seginit(void)
-{
-  struct cpu *c;
-
-  // Map "logical" addresses to virtual addresses using identity map.
-  // Cannot share a CODE descriptor for both kernel and user
-  // because it would have to have DPL_USR, but the CPU forbids
-  // an interrupt from CPL=0 to DPL=3.
-  c = &cpus[cpuid()];
-  c->gdt[SEG_KCODE] = SEG(STA_X|STA_R, 0, 0xffffffff, 0);
-  c->gdt[SEG_KDATA] = SEG(STA_W, 0, 0xffffffff, 0);
-  c->gdt[SEG_UCODE] = SEG(STA_X|STA_R, 0, 0xffffffff, DPL_USER);
-  c->gdt[SEG_UDATA] = SEG(STA_W, 0, 0xffffffff, DPL_USER);
-  lgdt(c->gdt, sizeof(c->gdt));
+seginit(void) {
+    struct cpu *c;
+
+    // Map "logical" addresses to virtual addresses using identity map.
+    // Cannot share a CODE descriptor for both kernel and user
+    // because it would have to have DPL_USR, but the CPU forbids
+    // an interrupt from CPL=0 to DPL=3.
+    c = &cpus[cpuid()];
+    c->gdt[SEG_KCODE] = SEG(STA_X | STA_R, 0, 0xffffffff, 0);
+    c->gdt[SEG_KDATA] = SEG(STA_W, 0, 0xffffffff, 0);
+    c->gdt[SEG_UCODE] = SEG(STA_X | STA_R, 0, 0xffffffff, DPL_USER);
+    c->gdt[SEG_UDATA] = SEG(STA_W, 0, 0xffffffff, DPL_USER);
+    lgdt(c->gdt, sizeof(c->gdt));
 }
 
 // Return the address of the PTE in page table pgdir
 // that corresponds to virtual address va.  If alloc!=0,
 // create any required page table pages.
 static pte_t *
-walkpgdir(pde_t *pgdir, const void *va, int alloc)
-{
-  pde_t *pde;
-  pte_t *pgtab;
-
-  pde = &pgdir[PDX(va)];
-  if(*pde & PTE_P){
-    pgtab = (pte_t*)P2V(PTE_ADDR(*pde));
-  } else {
-    if(!alloc || (pgtab = (pte_t*)kalloc()) == 0)
-      return 0;
-    // Make sure all those PTE_P bits are zero.
-    memset(pgtab, 0, PGSIZE);
-    // The permissions here are overly generous, but they can
-    // be further restricted by the permissions in the page table
-    // entries, if necessary.
-    *pde = V2P(pgtab) | PTE_P | PTE_W | PTE_U;
-  }
-  return &pgtab[PTX(va)];
+walkpgdir(pde_t *pgdir, const void *va, int alloc) {
+    pde_t *pde;
+    pte_t *pgtab;
+
+    pde = &pgdir[PDX(va)];
+    if (*pde & PTE_P) {
+        pgtab = (pte_t *) P2V(PTE_ADDR(*pde));
+    } else {
+        if (!alloc || (pgtab = (pte_t *) kalloc()) == 0)
+            return 0;
+        // Make sure all those PTE_P bits are zero.
+        memset(pgtab, 0, PGSIZE);
+        // The permissions here are overly generous, but they can
+        // be further restricted by the permissions in the page table
+        // entries, if necessary.
+        *pde = V2P(pgtab) | PTE_P | PTE_W | PTE_U;
+    }
+    return &pgtab[PTX(va)];
 }
 
 // Create PTEs for virtual addresses starting at va that refer to
 // physical addresses starting at pa. va and size might not
 // be page-aligned.
 static int
-mappages(pde_t *pgdir, void *va, uint size, uint pa, int perm)
-{
-  char *a, *last;
-  pte_t *pte;
-
-  a = (char*)PGROUNDDOWN((uint)va);
-  last = (char*)PGROUNDDOWN(((uint)va) + size - 1);
-  for(;;){
-    if((pte = walkpgdir(pgdir, a, 1)) == 0)
-      return -1;
-    if(*pte & PTE_P)
-      panic("remap");
-    *pte = pa | perm | PTE_P;
-    if(a == last)
-      break;
-    a += PGSIZE;
-    pa += PGSIZE;
-  }
-  return 0;
+mappages(pde_t *pgdir, void *va, uint size, uint pa, int perm) {
+    char *a, *last;
+    pte_t *pte;
+
+    a = (char *) PGROUNDDOWN((uint) va);
+    last = (char *) PGROUNDDOWN(((uint) va) + size - 1);
+    for (;;) {
+        if ((pte = walkpgdir(pgdir, a, 1)) == 0)
+            return -1;
+        if (*pte & PTE_P)
+            panic("remap");
+        *pte = pa | perm | PTE_P;
+        if (a == last)
+            break;
+        a += PGSIZE;
+        pa += PGSIZE;
+    }
+    return 0;
 }
 
 // There is one page table per process, plus one that's used when
@@ -103,149 +100,145 @@ mappages(pde_t *pgdir, void *va, uint size, uint pa, int perm)
 // This table defines the kernel's mappings, which are present in
 // every process's page table.
 static struct kmap {
-  void *virt;
-  uint phys_start;
-  uint phys_end;
-  int perm;
+    void *virt;
+    uint phys_start;
+    uint phys_end;
+    int perm;
 } kmap[] = {
- { (void*)KERNBASE, 0,             EXTMEM,    PTE_W}, // I/O space
- { (void*)KERNLINK, V2P(KERNLINK), V2P(data), 0},     // kern text+rodata
- { (void*)data,     V2P(data),     PHYSTOP,   PTE_W}, // kern data+memory
- { (void*)DEVSPACE, DEVSPACE,      0,         PTE_W}, // more devices
+        {(void *) KERNBASE, 0,             EXTMEM,  PTE_W}, // I/O space
+        {(void *) KERNLINK, V2P(KERNLINK), V2P(data), 0},     // kern text+rodata
+        {(void *) data,     V2P(data),     PHYSTOP, PTE_W}, // kern data+memory
+        {(void *) DEVSPACE, DEVSPACE, 0,            PTE_W}, // more devices
 };
 
 // Set up kernel part of a page table.
-pde_t*
-setupkvm(void)
-{
-  pde_t *pgdir;
-  struct kmap *k;
-
-  if((pgdir = (pde_t*)kalloc()) == 0)
-    return 0;
-  memset(pgdir, 0, PGSIZE);
-  if (P2V(PHYSTOP) > (void*)DEVSPACE)
-    panic("PHYSTOP too high");
-  for(k = kmap; k < &kmap[NELEM(kmap)]; k++)
-    if(mappages(pgdir, k->virt, k->phys_end - k->phys_start,
-                (uint)k->phys_start, k->perm) < 0) {
-      freevm(pgdir);
-      return 0;
+pde_t *
+setupkvm(void) {
+    pde_t *pgdir;
+    struct kmap *k;
+
+    if ((pgdir = (pde_t *) kalloc()) == 0)
+        return 0;
+    memset(pgdir, 0, PGSIZE);
+    if (P2V(PHYSTOP) > (void *) DEVSPACE)
+        panic("PHYSTOP too high");
+    for (k = kmap; k < &kmap[NELEM(kmap)];
+    k++)
+    if (mappages(pgdir, k->virt, k->phys_end - k->phys_start,
+                 (uint) k->phys_start, k->perm) < 0) {
+        freevm(pgdir);
+        return 0;
     }
-  return pgdir;
+    return pgdir;
 }
 
 // Allocate one page table for the machine for the kernel address
 // space for scheduler processes.
 void
-kvmalloc(void)
-{
-  kpgdir = setupkvm();
-  switchkvm();
+kvmalloc(void) {
+    kpgdir = setupkvm();
+    switchkvm();
 }
 
 // Switch h/w page table register to the kernel-only page table,
 // for when no process is running.
 void
-switchkvm(void)
-{
-  lcr3(V2P(kpgdir));   // switch to the kernel page table
+switchkvm(void) {
+    lcr3(V2P(kpgdir));   // switch to the kernel page table
 }
 
 // Switch TSS and h/w page table to correspond to process p.
 void
-switchuvm(struct proc *p)
-{
-  if(p == 0)
-    panic("switchuvm: no process");
-  if(p->kstack == 0)
-    panic("switchuvm: no kstack");
-  if(p->pgdir == 0)
-    panic("switchuvm: no pgdir");
-
-  pushcli();
-  mycpu()->gdt[SEG_TSS] = SEG16(STS_T32A, &mycpu()->ts,
-                                sizeof(mycpu()->ts)-1, 0);
-  mycpu()->gdt[SEG_TSS].s = 0;
-  mycpu()->ts.ss0 = SEG_KDATA << 3;
-  mycpu()->ts.esp0 = (uint)p->kstack + KSTACKSIZE;
-  // setting IOPL=0 in eflags *and* iomb beyond the tss segment limit
-  // forbids I/O instructions (e.g., inb and outb) from user space
-  mycpu()->ts.iomb = (ushort) 0xFFFF;
-  ltr(SEG_TSS << 3);
-  lcr3(V2P(p->pgdir));  // switch to process's address space
-  popcli();
+switchuvm(struct thread *t, struct proc *p) {
+    if (p == 0)
+        panic("switchuvm: no process");
+    if (t == 0)
+        panic("switchuvm: no thread");
+    if (t->kstack == 0)
+        panic("switchuvm: no kstack");
+    if (p->pgdir == 0)
+        panic("switchuvm: no pgdir");
+
+    pushcli();
+    mycpu()->gdt[SEG_TSS] = SEG16(STS_T32A, &mycpu()->ts,
+                                  sizeof(mycpu()->ts) - 1, 0);
+    mycpu()->gdt[SEG_TSS].s = 0;
+    mycpu()->ts.ss0 = SEG_KDATA << 3;
+    mycpu()->ts.esp0 = (uint) t->kstack + KSTACKSIZE;
+    // setting IOPL=0 in eflags *and* iomb beyond the tss segment limit
+    // forbids I/O instructions (e.g., inb and outb) from user space
+    mycpu()->ts.iomb = (ushort) 0xFFFF;
+    ltr(SEG_TSS << 3);
+    lcr3(V2P(p->pgdir));  // switch to process's address space
+    popcli();
 }
 
 // Load the initcode into address 0 of pgdir.
 // sz must be less than a page.
 void
-inituvm(pde_t *pgdir, char *init, uint sz)
-{
-  char *mem;
-
-  if(sz >= PGSIZE)
-    panic("inituvm: more than a page");
-  mem = kalloc();
-  memset(mem, 0, PGSIZE);
-  mappages(pgdir, 0, PGSIZE, V2P(mem), PTE_W|PTE_U);
-  memmove(mem, init, sz);
+inituvm(pde_t *pgdir, char *init, uint sz) {
+    char *mem;
+
+    if (sz >= PGSIZE)
+        panic("inituvm: more than a page");
+    mem = kalloc();
+    memset(mem, 0, PGSIZE);
+    mappages(pgdir, 0, PGSIZE, V2P(mem), PTE_W | PTE_U);
+    memmove(mem, init, sz);
 }
 
 // Load a program segment into pgdir.  addr must be page-aligned
 // and the pages from addr to addr+sz must already be mapped.
 int
-loaduvm(pde_t *pgdir, char *addr, struct inode *ip, uint offset, uint sz)
-{
-  uint i, pa, n;
-  pte_t *pte;
-
-  if((uint) addr % PGSIZE != 0)
-    panic("loaduvm: addr must be page aligned");
-  for(i = 0; i < sz; i += PGSIZE){
-    if((pte = walkpgdir(pgdir, addr+i, 0)) == 0)
-      panic("loaduvm: address should exist");
-    pa = PTE_ADDR(*pte);
-    if(sz - i < PGSIZE)
-      n = sz - i;
-    else
-      n = PGSIZE;
-    if(readi(ip, P2V(pa), offset+i, n) != n)
-      return -1;
-  }
-  return 0;
+loaduvm(pde_t *pgdir, char *addr, struct inode *ip, uint offset, uint sz) {
+    uint i, pa, n;
+    pte_t *pte;
+
+    if ((uint) addr % PGSIZE != 0)
+        panic("loaduvm: addr must be page aligned");
+    for (i = 0; i < sz; i += PGSIZE) {
+        if ((pte = walkpgdir(pgdir, addr + i, 0)) == 0)
+            panic("loaduvm: address should exist");
+        pa = PTE_ADDR(*pte);
+        if (sz - i < PGSIZE)
+            n = sz - i;
+        else
+            n = PGSIZE;
+        if (readi(ip, P2V(pa), offset + i, n) != n)
+            return -1;
+    }
+    return 0;
 }
 
 // Allocate page tables and physical memory to grow process from oldsz to
 // newsz, which need not be page aligned.  Returns new size or 0 on error.
 int
-allocuvm(pde_t *pgdir, uint oldsz, uint newsz)
-{
-  char *mem;
-  uint a;
-
-  if(newsz >= KERNBASE)
-    return 0;
-  if(newsz < oldsz)
-    return oldsz;
-
-  a = PGROUNDUP(oldsz);
-  for(; a < newsz; a += PGSIZE){
-    mem = kalloc();
-    if(mem == 0){
-      cprintf("allocuvm out of memory\n");
-      deallocuvm(pgdir, newsz, oldsz);
-      return 0;
-    }
-    memset(mem, 0, PGSIZE);
-    if(mappages(pgdir, (char*)a, PGSIZE, V2P(mem), PTE_W|PTE_U) < 0){
-      cprintf("allocuvm out of memory (2)\n");
-      deallocuvm(pgdir, newsz, oldsz);
-      kfree(mem);
-      return 0;
+allocuvm(pde_t *pgdir, uint oldsz, uint newsz) {
+    char *mem;
+    uint a;
+
+    if (newsz >= KERNBASE)
+        return 0;
+    if (newsz < oldsz)
+        return oldsz;
+
+    a = PGROUNDUP(oldsz);
+    for (; a < newsz; a += PGSIZE) {
+        mem = kalloc();
+        if (mem == 0) {
+            cprintf("allocuvm out of memory\n");
+            deallocuvm(pgdir, newsz, oldsz);
+            return 0;
+        }
+        memset(mem, 0, PGSIZE);
+        if (mappages(pgdir, (char *) a, PGSIZE, V2P(mem), PTE_W | PTE_U) < 0) {
+            cprintf("allocuvm out of memory (2)\n");
+            deallocuvm(pgdir, newsz, oldsz);
+            kfree(mem);
+            return 0;
+        }
     }
-  }
-  return newsz;
+    return newsz;
 }
 
 // Deallocate user pages to bring the process size from oldsz to
@@ -253,136 +246,130 @@ allocuvm(pde_t *pgdir, uint oldsz, uint newsz)
 // need to be less than oldsz.  oldsz can be larger than the actual
 // process size.  Returns the new process size.
 int
-deallocuvm(pde_t *pgdir, uint oldsz, uint newsz)
-{
-  pte_t *pte;
-  uint a, pa;
-
-  if(newsz >= oldsz)
-    return oldsz;
-
-  a = PGROUNDUP(newsz);
-  for(; a  < oldsz; a += PGSIZE){
-    pte = walkpgdir(pgdir, (char*)a, 0);
-    if(!pte)
-      a = PGADDR(PDX(a) + 1, 0, 0) - PGSIZE;
-    else if((*pte & PTE_P) != 0){
-      pa = PTE_ADDR(*pte);
-      if(pa == 0)
-        panic("kfree");
-      char *v = P2V(pa);
-      kfree(v);
-      *pte = 0;
+deallocuvm(pde_t *pgdir, uint oldsz, uint newsz) {
+    pte_t *pte;
+    uint a, pa;
+
+    if (newsz >= oldsz)
+        return oldsz;
+
+    a = PGROUNDUP(newsz);
+    for (; a < oldsz; a += PGSIZE) {
+        pte = walkpgdir(pgdir, (char *) a, 0);
+        if (!pte)
+            a = PGADDR(PDX(a) + 1, 0, 0) - PGSIZE;
+        else if ((*pte & PTE_P) != 0) {
+            pa = PTE_ADDR(*pte);
+            if (pa == 0)
+                panic("kfree");
+            char *v = P2V(pa);
+            kfree(v);
+            *pte = 0;
+        }
     }
-  }
-  return newsz;
+    return newsz;
 }
 
 // Free a page table and all the physical memory pages
 // in the user part.
 void
-freevm(pde_t *pgdir)
-{
-  uint i;
-
-  if(pgdir == 0)
-    panic("freevm: no pgdir");
-  deallocuvm(pgdir, KERNBASE, 0);
-  for(i = 0; i < NPDENTRIES; i++){
-    if(pgdir[i] & PTE_P){
-      char * v = P2V(PTE_ADDR(pgdir[i]));
-      kfree(v);
+freevm(pde_t *pgdir) {
+    uint i;
+
+    if (pgdir == 0)
+        panic("freevm: no pgdir");
+    deallocuvm(pgdir, KERNBASE, 0);
+    for (i = 0; i < NPDENTRIES; i++) {
+        if (pgdir[i] & PTE_P) {
+            char *v = P2V(PTE_ADDR(pgdir[i]));
+            kfree(v);
+        }
     }
-  }
-  kfree((char*)pgdir);
+    kfree((char *) pgdir);
 }
 
 // Clear PTE_U on a page. Used to create an inaccessible
 // page beneath the user stack.
 void
-clearpteu(pde_t *pgdir, char *uva)
-{
-  pte_t *pte;
-
-  pte = walkpgdir(pgdir, uva, 0);
-  if(pte == 0)
-    panic("clearpteu");
-  *pte &= ~PTE_U;
+clearpteu(pde_t *pgdir, char *uva) {
+    pte_t *pte;
+
+    pte = walkpgdir(pgdir, uva, 0);
+    if (pte == 0)
+        panic("clearpteu");
+    *pte &= ~PTE_U;
 }
 
 // Given a parent process's page table, create a copy
 // of it for a child.
-pde_t*
-copyuvm(pde_t *pgdir, uint sz)
-{
-  pde_t *d;
-  pte_t *pte;
-  uint pa, i, flags;
-  char *mem;
-
-  if((d = setupkvm()) == 0)
-    return 0;
-  for(i = 0; i < sz; i += PGSIZE){
-    if((pte = walkpgdir(pgdir, (void *) i, 0)) == 0)
-      panic("copyuvm: pte should exist");
-    if(!(*pte & PTE_P))
-      panic("copyuvm: page not present");
-    pa = PTE_ADDR(*pte);
-    flags = PTE_FLAGS(*pte);
-    if((mem = kalloc()) == 0)
-      goto bad;
-    memmove(mem, (char*)P2V(pa), PGSIZE);
-    if(mappages(d, (void*)i, PGSIZE, V2P(mem), flags) < 0) {
-      kfree(mem);
-      goto bad;
+pde_t *
+copyuvm(pde_t *pgdir, uint sz) {
+    pde_t *d;
+    pte_t *pte;
+    uint pa, i, flags;
+    char *mem;
+
+    if ((d = setupkvm()) == 0)
+        return 0;
+    for (i = 0; i < sz; i += PGSIZE) {
+        if ((pte = walkpgdir(pgdir, (void *) i, 0)) == 0)
+            panic("copyuvm: pte should exist");
+        if (!(*pte & PTE_P))
+            panic("copyuvm: page not present");
+        pa = PTE_ADDR(*pte);
+        flags = PTE_FLAGS(*pte);
+        if ((mem = kalloc()) == 0)
+            goto bad;
+        memmove(mem, (char *) P2V(pa), PGSIZE);
+        if (mappages(d, (void *) i, PGSIZE, V2P(mem), flags) < 0) {
+            kfree(mem);
+            goto bad;
+        }
     }
-  }
-  return d;
+    return d;
 
-bad:
-  freevm(d);
-  return 0;
+    bad:
+    freevm(d);
+    return 0;
 }
 
 //PAGEBREAK!
 // Map user virtual address to kernel address.
-char*
-uva2ka(pde_t *pgdir, char *uva)
-{
-  pte_t *pte;
-
-  pte = walkpgdir(pgdir, uva, 0);
-  if((*pte & PTE_P) == 0)
-    return 0;
-  if((*pte & PTE_U) == 0)
-    return 0;
-  return (char*)P2V(PTE_ADDR(*pte));
+char *
+uva2ka(pde_t *pgdir, char *uva) {
+    pte_t *pte;
+
+    pte = walkpgdir(pgdir, uva, 0);
+    if ((*pte & PTE_P) == 0)
+        return 0;
+    if ((*pte & PTE_U) == 0)
+        return 0;
+    return (char *) P2V(PTE_ADDR(*pte));
 }
 
 // Copy len bytes from p to user address va in page table pgdir.
 // Most useful when pgdir is not the current page table.
 // uva2ka ensures this only works for PTE_U pages.
 int
-copyout(pde_t *pgdir, uint va, void *p, uint len)
-{
-  char *buf, *pa0;
-  uint n, va0;
-
-  buf = (char*)p;
-  while(len > 0){
-    va0 = (uint)PGROUNDDOWN(va);
-    pa0 = uva2ka(pgdir, (char*)va0);
-    if(pa0 == 0)
-      return -1;
-    n = PGSIZE - (va - va0);
-    if(n > len)
-      n = len;
-    memmove(pa0 + (va - va0), buf, n);
-    len -= n;
-    buf += n;
-    va = va0 + PGSIZE;
-  }
-  return 0;
+copyout(pde_t *pgdir, uint va, void *p, uint len) {
+    char *buf, *pa0;
+    uint n, va0;
+
+    buf = (char *) p;
+    while (len > 0) {
+        va0 = (uint) PGROUNDDOWN(va);
+        pa0 = uva2ka(pgdir, (char *) va0);
+        if (pa0 == 0)
+            return -1;
+        n = PGSIZE - (va - va0);
+        if (n > len)
+            n = len;
+        memmove(pa0 + (va - va0), buf, n);
+        len -= n;
+        buf += n;
+        va = va0 + PGSIZE;
+    }
+    return 0;
 }
 
 //PAGEBREAK!
